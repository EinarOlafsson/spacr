spacr.deep_spacr
================

.. py:module:: spacr.deep_spacr






Module Contents
---------------

.. py:function:: apply_model(src, model_path, image_size=224, batch_size=64, normalize=True, n_jobs=10)

   Apply a trained binary classification model to a folder of images.

   Loads a PyTorch model and applies it to images in the specified folder using batch inference.
   Supports optional normalization and GPU acceleration. Outputs prediction probabilities and
   saves results as a CSV file alongside the model.

   :param src: Path to a folder containing input images (e.g., PNG, JPG).
   :type src: str
   :param model_path: Path to a trained PyTorch model file (.pt or .pth).
   :type model_path: str
   :param image_size: Size to center-crop input images to. Default is 224.
   :type image_size: int, optional
   :param batch_size: Number of images to process per batch. Default is 64.
   :type batch_size: int, optional
   :param normalize: If True, normalize images to [-1, 1] using ImageNet-style transform. Default is True.
   :type normalize: bool, optional
   :param n_jobs: Number of subprocesses to use for data loading. Default is 10.
   :type n_jobs: int, optional

   :returns:

             A DataFrame with two columns:
                 - "path": Filenames of processed images.
                 - "pred": Model output probabilities (sigmoid of logits).
   :rtype: pandas.DataFrame

   Saves:
       A CSV file named like <model_path><YYMMDD>_<ext>_test_result.csv, containing the prediction results.

   .. rubric:: Notes

   - Uses GPU if available, otherwise runs on CPU.
   - Assumes model outputs raw logits for binary classification (sigmoid is applied).
   - The input folder must contain only images readable by `PIL.Image.open`.


.. py:function:: apply_model_to_tar(settings={})

   Apply a trained model to images stored inside a tar archive.

   Loads a model and applies it to images within a `.tar` archive using batch inference. Results are
   filtered by a probability threshold and saved to a CSV. Supports GPU acceleration and normalization.

   :param settings: Dictionary with the following keys:
                    - tar_path (str): Path to the tar archive with input images.
                    - model_path (str): Path to the trained PyTorch model (.pt/.pth).
                    - image_size (int): Center crop size for input images. Default is 224.
                    - batch_size (int): Batch size for DataLoader. Default is 64.
                    - normalize (bool): Apply normalization to [-1, 1]. Default is True.
                    - n_jobs (int): Number of workers for data loading. Default is system CPU count - 4.
                    - verbose (bool): If True, print progress and model details.
                    - score_threshold (float): Probability threshold for positive classification (used in result filtering).
   :type settings: dict

   :returns:

             DataFrame with:
                 - "path": Filenames inside the tar archive.
                 - "pred": Model prediction scores (sigmoid output).
   :rtype: pandas.DataFrame

   Saves:
       A CSV file with prediction results to the same directory as the tar file.


.. py:function:: evaluate_model_performance(model, loader, epoch, loss_type)

   Evaluates the performance of a model on a given data loader.

   :param model: The model to evaluate.
   :type model: torch.nn.Module
   :param loader: The data loader to evaluate the model on.
   :type loader: torch.utils.data.DataLoader
   :param loader_name: The name of the data loader.
   :type loader_name: str
   :param epoch: The current epoch number.
   :type epoch: int
   :param loss_type: The type of loss function to use.
   :type loss_type: str

   :returns: The classification metrics data as a DataFrame.
             prediction_pos_probs (list): The positive class probabilities for each prediction.
             all_labels (list): The true labels for each prediction.
   :rtype: data_df (pandas.DataFrame)


.. py:function:: test_model_core(model, loader, loader_name, epoch, loss_type)

.. py:function:: test_model_performance(loaders, model, loader_name_list, epoch, loss_type)

   Test the performance of a model on given data loaders.

   :param loaders: List of data loaders.
   :type loaders: list
   :param model: The model to be tested.
   :param loader_name_list: List of names for the data loaders.
   :type loader_name_list: list
   :param epoch: The current epoch.
   :type epoch: int
   :param loss_type: The type of loss function.

   :returns: A tuple containing the test results and the results dataframe.
   :rtype: tuple


.. py:function:: train_test_model(settings)

.. py:function:: train_model(dst, model_type, train_loaders, epochs=100, learning_rate=0.0001, weight_decay=0.05, amsgrad=False, optimizer_type='adamw', use_checkpoint=False, dropout_rate=0, n_jobs=20, val_loaders=None, test_loaders=None, init_weights='imagenet', intermedeate_save=None, chan_dict=None, schedule=None, loss_type='binary_cross_entropy_with_logits', gradient_accumulation=False, gradient_accumulation_steps=4, channels=['r', 'g', 'b'], verbose=False)

   Trains a model using the specified parameters.

   :param dst: The destination path to save the model and results.
   :type dst: str
   :param model_type: The type of model to train.
   :type model_type: str
   :param train_loaders: A list of training data loaders.
   :type train_loaders: list
   :param epochs: The number of training epochs. Defaults to 100.
   :type epochs: int, optional
   :param learning_rate: The learning rate for the optimizer. Defaults to 0.0001.
   :type learning_rate: float, optional
   :param weight_decay: The weight decay for the optimizer. Defaults to 0.05.
   :type weight_decay: float, optional
   :param amsgrad: Whether to use AMSGrad for the optimizer. Defaults to False.
   :type amsgrad: bool, optional
   :param optimizer_type: The type of optimizer to use. Defaults to 'adamw'.
   :type optimizer_type: str, optional
   :param use_checkpoint: Whether to use checkpointing during training. Defaults to False.
   :type use_checkpoint: bool, optional
   :param dropout_rate: The dropout rate for the model. Defaults to 0.
   :type dropout_rate: float, optional
   :param n_jobs: The number of n_jobs for data loading. Defaults to 20.
   :type n_jobs: int, optional
   :param val_loaders: A list of validation data loaders. Defaults to None.
   :type val_loaders: list, optional
   :param test_loaders: A list of test data loaders. Defaults to None.
   :type test_loaders: list, optional
   :param init_weights: The initialization weights for the model. Defaults to 'imagenet'.
   :type init_weights: str, optional
   :param intermedeate_save: The intermediate save thresholds. Defaults to None.
   :type intermedeate_save: list, optional
   :param chan_dict: The channel dictionary. Defaults to None.
   :type chan_dict: dict, optional
   :param schedule: The learning rate schedule. Defaults to None.
   :type schedule: str, optional
   :param loss_type: The loss function type. Defaults to 'binary_cross_entropy_with_logits'.
   :type loss_type: str, optional
   :param gradient_accumulation: Whether to use gradient accumulation. Defaults to False.
   :type gradient_accumulation: bool, optional
   :param gradient_accumulation_steps: The number of steps for gradient accumulation. Defaults to 4.
   :type gradient_accumulation_steps: int, optional

   :returns: None


.. py:function:: generate_activation_map(settings)

.. py:function:: visualize_classes(model, dtype, class_names, **kwargs)

.. py:function:: visualize_integrated_gradients(src, model_path, target_label_idx=0, image_size=224, channels=[1, 2, 3], normalize=True, save_integrated_grads=False, save_dir='integrated_grads')

.. py:class:: SmoothGrad(model, n_samples=50, stdev_spread=0.15)

   .. py:attribute:: model


   .. py:attribute:: n_samples
      :value: 50



   .. py:attribute:: stdev_spread
      :value: 0.15



   .. py:method:: compute_smooth_grad(input_tensor, target_class)


.. py:function:: visualize_smooth_grad(src, model_path, target_label_idx, image_size=224, channels=[1, 2, 3], normalize=True, save_smooth_grad=False, save_dir='smooth_grad')

.. py:function:: deep_spacr(settings={})

   Run deep learning-based classification workflow on microscopy data using SpaCr.

   This function handles dataset generation, model training, and inference using a trained model on tar-archived image datasets.
   Settings are filled using `deep_spacr_defaults`.

   :param settings: Dictionary of settings with the following keys:

                    General:
                        - src (str): Path to the input dataset.
                        - dataset (str): Path to a dataset archive.
                        - dataset_mode (str): Dataset generation mode. Typically 'metadata'.
                        - file_type (str): Type of input files (e.g., 'cell_png').
                        - file_metadata (str or None): Path to file-level metadata, if available.
                        - sample (int or None): Limit to N random samples for development/testing.
                        - experiment (str): Experiment name prefix. Default is 'exp.'.

                    Annotation and class mapping:
                        - annotation_column (str): Metadata column containing class annotations.
                        - annotated_classes (list): List of class IDs used for training (e.g., [1, 2]).
                        - classes (list): Class labels (e.g., ['nc', 'pc']).
                        - class_metadata (list of lists): Mapping of classes to metadata terms (e.g., [['c1'], ['c2']]).
                        - metadata_type_by (str): How to interpret metadata structure. Typically 'columnID'.

                    Image processing:
                        - channel_of_interest (int): Channel index to use for classification.
                        - png_type (str): Type of image format (e.g., 'cell_png').
                        - image_size (int): Input size (e.g., 224 for 224x224 crop).
                        - train_channels (list): Channels to use for training (e.g., ['r', 'g', 'b']).
                        - normalize (bool): Whether to normalize input images. Default is True.
                        - augment (bool): Whether to apply data augmentation.

                    Model and training:
                        - model_type (str): Model architecture (e.g., 'maxvit_t').
                        - optimizer_type (str): Optimizer (e.g., 'adamw').
                        - schedule (str): Learning rate scheduler ('reduce_lr_on_plateau' or 'step_lr').
                        - loss_type (str): Loss function ('focal_loss' or 'binary_cross_entropy_with_logits').
                        - dropout_rate (float): Dropout probability.
                        - init_weights (bool): Initialize model with pretrained weights.
                        - amsgrad (bool): Use AMSGrad variant of AdamW optimizer.
                        - use_checkpoint (bool): Enable checkpointing.
                        - intermedeate_save (bool): Save intermediate models during training.

                    Training control:
                        - train (bool): Enable training phase.
                        - test (bool): Enable evaluation on test set.
                        - train_DL_model (bool): Enable deep learning model training.
                        - generate_training_dataset (bool): Enable generation of train/test splits.
                        - test_split (float): Proportion of data used for testing.
                        - val_split (float): Fraction of training set used for validation.
                        - epochs (int): Number of training epochs.
                        - batch_size (int): Batch size for training and inference.
                        - learning_rate (float): Learning rate.
                        - weight_decay (float): L2 regularization strength.
                        - gradient_accumulation (bool): Accumulate gradients over multiple steps.
                        - gradient_accumulation_steps (int): Number of steps per gradient update.

                    Inference:
                        - apply_model_to_dataset (bool): Run prediction on tar dataset.
                        - tar_path (str): Path to tar file for inference input.
                        - model_path (str): Path to trained model file.
                        - score_threshold (float): Probability threshold for binary classification.

                    Execution:
                        - n_jobs (int): Number of parallel workers.
                        - pin_memory (bool): Whether to use pinned memory in DataLoader.
                        - verbose (bool): Print training and evaluation progress.
   :type settings: dict

   :returns: None. All outputs (trained models, predictions, settings) are saved to disk.


.. py:function:: model_knowledge_transfer(teacher_paths, student_save_path, data_loader, device='cpu', student_model_name='maxvit_t', pretrained=True, dropout_rate=None, use_checkpoint=False, alpha=0.5, temperature=2.0, lr=0.0001, epochs=10)

.. py:function:: model_fusion(model_paths, save_path, device='cpu', model_name='maxvit_t', pretrained=True, dropout_rate=None, use_checkpoint=False, aggregator='mean')

.. py:function:: annotate_filter_vision(settings)

