spacr.io
========

.. py:module:: spacr.io






Module Contents
---------------

.. py:function:: process_non_tif_non_2D_images(folder)

   Processes all images in the folder and splits them into grayscale channels, preserving bit depth.


.. py:class:: CombineLoaders(train_loaders)

   A class that combines multiple data loaders into a single iterator.

   :param train_loaders: A list of data loaders.
   :type train_loaders: list

   :raises StopIteration: If all data loaders have been exhausted.


   .. py:attribute:: train_loaders


   .. py:attribute:: loader_iters


.. py:class:: CombinedDataset(datasets, shuffle=True)

   Bases: :py:obj:`torch.utils.data.Dataset`


   A dataset that combines multiple datasets into one.

   :param datasets: A list of datasets to be combined.
   :type datasets: list
   :param shuffle: Whether to shuffle the combined dataset. Defaults to True.
   :type shuffle: bool, optional


   .. py:attribute:: datasets


   .. py:attribute:: lengths


   .. py:attribute:: total_length


   .. py:attribute:: shuffle
      :value: True



.. py:class:: NoClassDataset(data_dir, transform=None, shuffle=True, load_to_memory=False)

   Bases: :py:obj:`torch.utils.data.Dataset`


   A custom dataset class for handling image data without class labels.

   :param data_dir: The directory path where the image files are located.
   :type data_dir: str
   :param transform: A function/transform to apply to the image data. Default is None.
   :type transform: callable, optional
   :param shuffle: Whether to shuffle the dataset. Default is True.
   :type shuffle: bool, optional
   :param load_to_memory: Whether to load all images into memory. Default is False.
   :type load_to_memory: bool, optional


   .. py:attribute:: data_dir


   .. py:attribute:: transform
      :value: None



   .. py:attribute:: shuffle
      :value: True



   .. py:attribute:: load_to_memory
      :value: False



   .. py:attribute:: filenames


   .. py:method:: load_image(img_path)

      Load an image from the given file path.

      :param img_path: The file path of the image.
      :type img_path: str

      :returns: The loaded image.
      :rtype: PIL.Image



   .. py:method:: shuffle_dataset()

      Shuffle the dataset.



.. py:class:: spacrDataset(data_dir, loader_classes, transform=None, shuffle=True, pin_memory=False, specific_files=None, specific_labels=None)

   Bases: :py:obj:`torch.utils.data.Dataset`


   Custom PyTorch Dataset for loading labeled image data organized by class folders or from specified file lists.

   :param data_dir: Root directory containing subfolders for each class.
   :type data_dir: str
   :param loader_classes: List of class names corresponding to subfolder names in `data_dir`.
   :type loader_classes: list[str]
   :param transform: Transform to apply to images (e.g., torchvision transforms).
   :type transform: callable, optional
   :param shuffle: Whether to shuffle the dataset. Default is True.
   :type shuffle: bool
   :param pin_memory: If True, pre-load all images into memory using multiprocessing. Default is False.
   :type pin_memory: bool
   :param specific_files: Specific image file paths to load instead of scanning `data_dir`.
   :type specific_files: list[str], optional
   :param specific_labels: Corresponding labels for `specific_files`.
   :type specific_labels: list[int], optional


   .. py:attribute:: data_dir


   .. py:attribute:: classes


   .. py:attribute:: transform
      :value: None



   .. py:attribute:: shuffle
      :value: True



   .. py:attribute:: pin_memory
      :value: False



   .. py:attribute:: filenames
      :value: []



   .. py:attribute:: labels
      :value: []



   .. py:method:: load_image(img_path)


   .. py:method:: shuffle_dataset()


   .. py:method:: get_plate(filepath)


.. py:class:: spacrDataLoader(*args, preload_batches=1, **kwargs)

   Bases: :py:obj:`torch.utils.data.DataLoader`


   Custom DataLoader with background batch preloading support using multiprocessing.

   Extends:
       torch.utils.data.DataLoader

   :param \*args: Arguments passed to the base DataLoader.
   :param preload_batches: Number of batches to preload in a background process. Default is 1.
   :type preload_batches: int
   :param \*\*kwargs: Keyword arguments passed to the base DataLoader. Supports all standard DataLoader arguments.


   .. py:attribute:: preload_batches
      :value: 1



   .. py:attribute:: batch_queue


   .. py:attribute:: process
      :value: None



   .. py:attribute:: current_batch_index
      :value: 0



   .. py:attribute:: pin_memory


   .. py:method:: cleanup()


.. py:class:: TarImageDataset(tar_path, transform=None)

   Bases: :py:obj:`torch.utils.data.Dataset`


   A PyTorch Dataset for loading images directly from a .tar archive without extraction.

   This is useful for large datasets stored as compressed tar archives, enabling on-the-fly
   access to individual image files without unpacking the archive to disk.

   :param tar_path: Path to the .tar archive containing image files.
   :type tar_path: str
   :param transform: Optional transform to be applied on a sample.
   :type transform: callable, optional

   .. attribute:: members

      List of image members in the tar archive.

      :type: List[TarInfo]


   .. py:attribute:: tar_path


   .. py:attribute:: transform
      :value: None



.. py:function:: load_images_from_paths(images_by_key)

   Load images from a dictionary mapping keys to lists of image file paths.

   Each key in the input dictionary corresponds to a list of file paths. The function
   loads each image as a NumPy array and returns a new dictionary with the same keys,
   where each value is a list of loaded images.

   :param images_by_key: A dictionary where each key maps to a list of image file paths (str).
   :type images_by_key: dict

   :returns: A dictionary where each key maps to a list of NumPy arrays representing the loaded images.
   :rtype: dict

   .. rubric:: Notes

   - Images are loaded using PIL and converted to NumPy arrays.
   - Any image that fails to load will be skipped, and an error message will be printed.


.. py:function:: concatenate_and_normalize(src, channels, save_dtype=np.float32, settings={})

   Concatenates and normalizes channel data from multiple files and saves the normalized data.

   :param src: The source directory containing the channel data files.
   :type src: str
   :param channels: The list of channel indices to be concatenated and normalized.
   :type channels: list
   :param randomize: Whether to randomize the order of the files. Defaults to True.
   :type randomize: bool, optional
   :param timelapse: Whether the channel data is from a timelapse experiment. Defaults to False.
   :type timelapse: bool, optional
   :param batch_size: The number of files to be processed in each batch. Defaults to 100.
   :type batch_size: int, optional
   :param backgrounds: Background values for each channel. Defaults to [100, 100, 100].
   :type backgrounds: list, optional
   :param remove_backgrounds: Whether to remove background values for each channel. Defaults to [False, False, False].
   :type remove_backgrounds: list, optional
   :param lower_percentile: Lower percentile value for normalization. Defaults to 2.
   :type lower_percentile: int, optional
   :param save_dtype: Data type for saving the normalized stack. Defaults to np.float32.
   :type save_dtype: numpy.dtype, optional
   :param signal_to_noise: Signal-to-noise ratio thresholds for each channel. Defaults to [5, 5, 5].
   :type signal_to_noise: list, optional
   :param signal_thresholds: Signal thresholds for each channel. Defaults to [1000, 1000, 1000].
   :type signal_thresholds: list, optional

   :returns: The directory path where the concatenated and normalized channel data is saved.
   :rtype: str


.. py:function:: delete_empty_subdirectories(folder_path)

   Deletes all empty subdirectories in the specified folder.

   Args:
   - folder_path (str): The path to the folder in which to look for empty subdirectories.


.. py:function:: preprocess_img_data(settings)

   Preprocesses image data by converting z-stack images to maximum intensity projection (MIP) images.

   :param src: The source directory containing the z-stack images.
   :type src: str
   :param metadata_type: The type of metadata associated with the images. Defaults to 'cellvoyager'.
   :type metadata_type: str, optional
   :param custom_regex: The custom regular expression pattern used to match the filenames of the z-stack images. Defaults to None.
   :type custom_regex: str, optional
   :param cmap: The colormap used for plotting. Defaults to 'inferno'.
   :type cmap: str, optional
   :param figuresize: The size of the figure for plotting. Defaults to 15.
   :type figuresize: int, optional
   :param normalize: Whether to normalize the images. Defaults to False.
   :type normalize: bool, optional
   :param nr: The number of images to preprocess. Defaults to 1.
   :type nr: int, optional
   :param plot: Whether to plot the images. Defaults to False.
   :type plot: bool, optional
   :param mask_channels: The channels to use for masking. Defaults to [0, 1, 2].
   :type mask_channels: list, optional
   :param batch_size: The number of images to process in each batch. Defaults to [100, 100, 100].
   :type batch_size: list, optional
   :param timelapse: Whether the images are from a timelapse experiment. Defaults to False.
   :type timelapse: bool, optional
   :param remove_background: Whether to remove the background from the images. Defaults to False.
   :type remove_background: bool, optional
   :param backgrounds: The number of background images to use for background removal. Defaults to 100.
   :type backgrounds: int, optional
   :param lower_percentile: The lower percentile used for background removal. Defaults to 1.
   :type lower_percentile: float, optional
   :param save_dtype: The data type used for saving the preprocessed images. Defaults to np.float32.
   :type save_dtype: type, optional
   :param randomize: Whether to randomize the order of the images. Defaults to True.
   :type randomize: bool, optional
   :param all_to_mip: Whether to convert all images to MIP. Defaults to False.
   :type all_to_mip: bool, optional
   :param settings: Additional settings for preprocessing. Defaults to {}.
   :type settings: dict, optional

   :returns: None


.. py:function:: read_plot_model_stats(train_file_path, val_file_path, save=False)

.. py:function:: convert_numpy_to_tiff(folder_path, limit=None)

   Converts all numpy files in a folder to TIFF format and saves them in a subdirectory 'tiff'.

   Args:
   folder_path (str): The path to the folder containing numpy files.


.. py:function:: generate_cellpose_train_test(src, test_split=0.1)

.. py:function:: parse_gz_files(folder_path)

   Parses the .fastq.gz files in the specified folder path and returns a dictionary
   containing the sample names and their corresponding file paths.

   :param folder_path: The path to the folder containing the .fastq.gz files.
   :type folder_path: str

   :returns: A dictionary where the keys are the sample names and the values are
             dictionaries containing the file paths for the 'R1' and 'R2' read directions.
   :rtype: dict


.. py:function:: generate_dataset(settings={})

.. py:function:: generate_loaders(src, mode='train', image_size=224, batch_size=32, classes=['nc', 'pc'], n_jobs=None, validation_split=0.0, pin_memory=False, normalize=False, channels=[1, 2, 3], augment=False, verbose=False)

   Generate data loaders for training and validation/test datasets.

   Parameters:
   - src (str): The source directory containing the data.
   - mode (str): The mode of operation. Options are 'train' or 'test'.
   - image_size (int): The size of the input images.
   - batch_size (int): The batch size for the data loaders.
   - classes (list): The list of classes to consider.
   - n_jobs (int): The number of worker threads for data loading.
   - validation_split (float): The fraction of data to use for validation.
   - pin_memory (bool): Whether to pin memory for faster data transfer.
   - normalize (bool): Whether to normalize the input images.
   - verbose (bool): Whether to print additional information and show images.
   - channels (list): The list of channels to retain. Options are [1, 2, 3] for all channels, [1, 2] for blue and green, etc.

   Returns:
   - train_loaders (list): List of data loaders for training datasets.
   - val_loaders (list): List of data loaders for validation datasets.


.. py:function:: generate_training_dataset(settings)

.. py:function:: training_dataset_from_annotation(db_path, dst, annotation_column='test', annotated_classes=(1, 2))

.. py:function:: training_dataset_from_annotation_metadata(db_path, dst, annotation_column='test', annotated_classes=(1, 2), metadata_type_by='columnID', class_metadata=['c1', 'c2'])

.. py:function:: generate_dataset_from_lists(dst, class_data, classes, test_split=0.1)

.. py:function:: convert_separate_files_to_yokogawa(folder, regex)

.. py:function:: convert_to_yokogawa(folder)

   Detects file type in the folder and converts them
   to Yokogawa-style naming with Maximum Intensity Projection (MIP).


.. py:function:: apply_augmentation(image, method)

.. py:function:: process_instruction(entry)

.. py:function:: prepare_cellpose_dataset(input_root, augment_data=False, train_fraction=0.8, n_jobs=None)

