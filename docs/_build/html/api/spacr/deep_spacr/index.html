

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>spacr.deep_spacr &mdash; spacr 1.0.8 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../../_static/graphviz.css?v=fd3f3429" />
      <link rel="stylesheet" type="text/css" href="../../../_static/custom.css?v=45a07ac9" />

  
      <script src="../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../_static/documentation_options.js?v=aec50437"></script>
      <script src="../../../_static/doctools.js?v=9a2dae69"></script>
      <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #005f73" >

          
          
          <a href="../../../index.html">
            
              <img src="../../../_static/logo_spacr.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../index.html">API Reference</a><ul class="simple">
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: #005f73" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">spacr</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">spacr.deep_spacr</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../_sources/api/spacr/deep_spacr/index.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-spacr.deep_spacr">
<span id="spacr-deep-spacr"></span><h1>spacr.deep_spacr<a class="headerlink" href="#module-spacr.deep_spacr" title="Link to this heading"></a></h1>
<section id="module-contents">
<h2>Module Contents<a class="headerlink" href="#module-contents" title="Link to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="spacr.deep_spacr.apply_model">
<span class="sig-prename descclassname"><span class="pre">spacr.deep_spacr.</span></span><span class="sig-name descname"><span class="pre">apply_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">src</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">image_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">224</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/spacr/deep_spacr.html#apply_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#spacr.deep_spacr.apply_model" title="Link to this definition"></a></dt>
<dd><p>Apply a trained binary classification model to a folder of images.</p>
<p>Loads a PyTorch model and applies it to images in the specified folder using batch inference.
Supports optional normalization and GPU acceleration. Outputs prediction probabilities and
saves results as a CSV file alongside the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>src</strong> (<em>str</em>) – Path to a folder containing input images (e.g., PNG, JPG).</p></li>
<li><p><strong>model_path</strong> (<em>str</em>) – Path to a trained PyTorch model file (.pt or .pth).</p></li>
<li><p><strong>image_size</strong> (<em>int</em><em>, </em><em>optional</em>) – Size to center-crop input images to. Default is 224.</p></li>
<li><p><strong>batch_size</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of images to process per batch. Default is 64.</p></li>
<li><p><strong>normalize</strong> (<em>bool</em><em>, </em><em>optional</em>) – If True, normalize images to [-1, 1] using ImageNet-style transform. Default is True.</p></li>
<li><p><strong>n_jobs</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of subprocesses to use for data loading. Default is 10.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>A DataFrame with two columns:</dt><dd><ul class="simple">
<li><p>”path”: Filenames of processed images.</p></li>
<li><p>”pred”: Model output probabilities (sigmoid of logits).</p></li>
</ul>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>pandas.DataFrame</p>
</dd>
</dl>
<dl class="simple">
<dt>Saves:</dt><dd><p>A CSV file named like &lt;model_path&gt;&lt;YYMMDD&gt;_&lt;ext&gt;_test_result.csv, containing the prediction results.</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<ul class="simple">
<li><p>Uses GPU if available, otherwise runs on CPU.</p></li>
<li><p>Assumes model outputs raw logits for binary classification (sigmoid is applied).</p></li>
<li><p>The input folder must contain only images readable by <cite>PIL.Image.open</cite>.</p></li>
</ul>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="spacr.deep_spacr.apply_model_to_tar">
<span class="sig-prename descclassname"><span class="pre">spacr.deep_spacr.</span></span><span class="sig-name descname"><span class="pre">apply_model_to_tar</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">settings</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/spacr/deep_spacr.html#apply_model_to_tar"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#spacr.deep_spacr.apply_model_to_tar" title="Link to this definition"></a></dt>
<dd><p>Apply a trained model to images stored inside a tar archive.</p>
<p>Loads a model and applies it to images within a <cite>.tar</cite> archive using batch inference. Results are
filtered by a probability threshold and saved to a CSV. Supports GPU acceleration and normalization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>settings</strong> (<em>dict</em>) – Dictionary with the following keys:
- tar_path (str): Path to the tar archive with input images.
- model_path (str): Path to the trained PyTorch model (.pt/.pth).
- image_size (int): Center crop size for input images. Default is 224.
- batch_size (int): Batch size for DataLoader. Default is 64.
- normalize (bool): Apply normalization to [-1, 1]. Default is True.
- n_jobs (int): Number of workers for data loading. Default is system CPU count - 4.
- verbose (bool): If True, print progress and model details.
- score_threshold (float): Probability threshold for positive classification (used in result filtering).</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>DataFrame with:</dt><dd><ul class="simple">
<li><p>”path”: Filenames inside the tar archive.</p></li>
<li><p>”pred”: Model prediction scores (sigmoid output).</p></li>
</ul>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>pandas.DataFrame</p>
</dd>
</dl>
<dl class="simple">
<dt>Saves:</dt><dd><p>A CSV file with prediction results to the same directory as the tar file.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="spacr.deep_spacr.evaluate_model_performance">
<span class="sig-prename descclassname"><span class="pre">spacr.deep_spacr.</span></span><span class="sig-name descname"><span class="pre">evaluate_model_performance</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_type</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/spacr/deep_spacr.html#evaluate_model_performance"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#spacr.deep_spacr.evaluate_model_performance" title="Link to this definition"></a></dt>
<dd><p>Evaluates the performance of a model on a given data loader.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>torch.nn.Module</em>) – The model to evaluate.</p></li>
<li><p><strong>loader</strong> (<em>torch.utils.data.DataLoader</em>) – The data loader to evaluate the model on.</p></li>
<li><p><strong>loader_name</strong> (<em>str</em>) – The name of the data loader.</p></li>
<li><p><strong>epoch</strong> (<em>int</em>) – The current epoch number.</p></li>
<li><p><strong>loss_type</strong> (<em>str</em>) – The type of loss function to use.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The classification metrics data as a DataFrame.
prediction_pos_probs (list): The positive class probabilities for each prediction.
all_labels (list): The true labels for each prediction.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>data_df (pandas.DataFrame)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="spacr.deep_spacr.test_model_core">
<span class="sig-prename descclassname"><span class="pre">spacr.deep_spacr.</span></span><span class="sig-name descname"><span class="pre">test_model_core</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loader_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_type</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/spacr/deep_spacr.html#test_model_core"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#spacr.deep_spacr.test_model_core" title="Link to this definition"></a></dt>
<dd><p>Evaluate a trained model on a test DataLoader and return performance metrics and predictions.</p>
<p>This function evaluates a binary classification model using a specified loss function, computes
classification metrics, and logs predictions, targets, and file-level results.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>torch.nn.Module</em>) – The trained PyTorch model to evaluate.</p></li>
<li><p><strong>loader</strong> (<em>torch.utils.data.DataLoader</em>) – DataLoader providing test data and labels.</p></li>
<li><p><strong>loader_name</strong> (<em>str</em>) – Identifier name for the loader (used for logging/debugging).</p></li>
<li><p><strong>epoch</strong> (<em>int</em>) – Current epoch number (used for metric tracking).</p></li>
<li><p><strong>loss_type</strong> (<em>str</em>) – Type of loss function to use for reporting (e.g., ‘bce’, ‘focal’).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p>data_df (pd.DataFrame): DataFrame containing classification metrics for the test set.</p></li>
<li><p>prediction_pos_probs (list): List of predicted probabilities for the positive class.</p></li>
<li><p>all_labels (list): Ground truth binary labels.</p></li>
<li><p>results_df (pd.DataFrame): Per-sample results, including filename, true label, predicted label,
and probability for class 1.</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="spacr.deep_spacr.test_model_performance">
<span class="sig-prename descclassname"><span class="pre">spacr.deep_spacr.</span></span><span class="sig-name descname"><span class="pre">test_model_performance</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">loaders</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loader_name_list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_type</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/spacr/deep_spacr.html#test_model_performance"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#spacr.deep_spacr.test_model_performance" title="Link to this definition"></a></dt>
<dd><p>Test the performance of a model on given data loaders.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>loaders</strong> (<em>list</em>) – List of data loaders.</p></li>
<li><p><strong>model</strong> – The model to be tested.</p></li>
<li><p><strong>loader_name_list</strong> (<em>list</em>) – List of names for the data loaders.</p></li>
<li><p><strong>epoch</strong> (<em>int</em>) – The current epoch.</p></li>
<li><p><strong>loss_type</strong> – The type of loss function.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tuple containing the test results and the results dataframe.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="spacr.deep_spacr.train_test_model">
<span class="sig-prename descclassname"><span class="pre">spacr.deep_spacr.</span></span><span class="sig-name descname"><span class="pre">train_test_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">settings</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/spacr/deep_spacr.html#train_test_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#spacr.deep_spacr.train_test_model" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="spacr.deep_spacr.train_model">
<span class="sig-prename descclassname"><span class="pre">spacr.deep_spacr.</span></span><span class="sig-name descname"><span class="pre">train_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dst</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_type</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_loaders</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_decay</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">amsgrad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'adamw'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_checkpoint</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">val_loaders</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_loaders</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'imagenet'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">intermedeate_save</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">chan_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">schedule</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'binary_cross_entropy_with_logits'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradient_accumulation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradient_accumulation_steps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">channels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">['r',</span> <span class="pre">'g',</span> <span class="pre">'b']</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/spacr/deep_spacr.html#train_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#spacr.deep_spacr.train_model" title="Link to this definition"></a></dt>
<dd><p>Trains a model using the specified parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dst</strong> (<em>str</em>) – The destination path to save the model and results.</p></li>
<li><p><strong>model_type</strong> (<em>str</em>) – The type of model to train.</p></li>
<li><p><strong>train_loaders</strong> (<em>list</em>) – A list of training data loaders.</p></li>
<li><p><strong>epochs</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of training epochs. Defaults to 100.</p></li>
<li><p><strong>learning_rate</strong> (<em>float</em><em>, </em><em>optional</em>) – The learning rate for the optimizer. Defaults to 0.0001.</p></li>
<li><p><strong>weight_decay</strong> (<em>float</em><em>, </em><em>optional</em>) – The weight decay for the optimizer. Defaults to 0.05.</p></li>
<li><p><strong>amsgrad</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to use AMSGrad for the optimizer. Defaults to False.</p></li>
<li><p><strong>optimizer_type</strong> (<em>str</em><em>, </em><em>optional</em>) – The type of optimizer to use. Defaults to ‘adamw’.</p></li>
<li><p><strong>use_checkpoint</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to use checkpointing during training. Defaults to False.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em><em>, </em><em>optional</em>) – The dropout rate for the model. Defaults to 0.</p></li>
<li><p><strong>n_jobs</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of n_jobs for data loading. Defaults to 20.</p></li>
<li><p><strong>val_loaders</strong> (<em>list</em><em>, </em><em>optional</em>) – A list of validation data loaders. Defaults to None.</p></li>
<li><p><strong>test_loaders</strong> (<em>list</em><em>, </em><em>optional</em>) – A list of test data loaders. Defaults to None.</p></li>
<li><p><strong>init_weights</strong> (<em>str</em><em>, </em><em>optional</em>) – The initialization weights for the model. Defaults to ‘imagenet’.</p></li>
<li><p><strong>intermedeate_save</strong> (<em>list</em><em>, </em><em>optional</em>) – The intermediate save thresholds. Defaults to None.</p></li>
<li><p><strong>chan_dict</strong> (<em>dict</em><em>, </em><em>optional</em>) – The channel dictionary. Defaults to None.</p></li>
<li><p><strong>schedule</strong> (<em>str</em><em>, </em><em>optional</em>) – The learning rate schedule. Defaults to None.</p></li>
<li><p><strong>loss_type</strong> (<em>str</em><em>, </em><em>optional</em>) – The loss function type. Defaults to ‘binary_cross_entropy_with_logits’.</p></li>
<li><p><strong>gradient_accumulation</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to use gradient accumulation. Defaults to False.</p></li>
<li><p><strong>gradient_accumulation_steps</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of steps for gradient accumulation. Defaults to 4.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="spacr.deep_spacr.generate_activation_map">
<span class="sig-prename descclassname"><span class="pre">spacr.deep_spacr.</span></span><span class="sig-name descname"><span class="pre">generate_activation_map</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">settings</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/spacr/deep_spacr.html#generate_activation_map"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#spacr.deep_spacr.generate_activation_map" title="Link to this definition"></a></dt>
<dd><p>Generate activation maps (Grad-CAM or saliency) from a trained model applied to a dataset stored in a tar archive.</p>
<p>This function loads a model, computes class activation maps or saliency maps for each input image, and saves the
results as images. Optionally, it plots batch-wise grids of maps and stores correlation results and image metadata
into an SQL database.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>settings</strong> (<em>dict</em>) – <p>Dictionary of parameters controlling activation map generation. Key fields include:</p>
<dl class="simple">
<dt>Required paths:</dt><dd><ul class="simple">
<li><p>dataset (str): Path to the <cite>.tar</cite> archive containing images.</p></li>
<li><p>model_path (str): Path to the trained PyTorch model (.pt or .pth).</p></li>
</ul>
</dd>
<dt>Model and method:</dt><dd><ul class="simple">
<li><p>model_type (str): Model architecture used (e.g., ‘maxvit’).</p></li>
<li><p>cam_type (str): One of [‘gradcam’, ‘gradcam_pp’, ‘saliency_image’, ‘saliency_channel’].</p></li>
<li><p>target_layer (str or None): Name of the target layer for Grad-CAM (optional, required for Grad-CAM variants).</p></li>
</ul>
</dd>
<dt>Input transforms:</dt><dd><ul class="simple">
<li><p>image_size (int): Size to center-crop images to (e.g., 224).</p></li>
<li><p>normalize_input (bool): Whether to normalize images to [-1, 1] range.</p></li>
<li><p>channels (list): Channel indices to select from input data (e.g., [0,1,2]).</p></li>
</ul>
</dd>
<dt>Inference:</dt><dd><ul class="simple">
<li><p>batch_size (int): Number of images per inference batch.</p></li>
<li><p>shuffle (bool): Whether to shuffle image order in DataLoader.</p></li>
<li><p>n_jobs (int): Number of parallel DataLoader workers (default is CPU count - 4).</p></li>
</ul>
</dd>
<dt>Output control:</dt><dd><ul class="simple">
<li><p>save (bool): If True, saves individual activation maps to disk.</p></li>
<li><p>plot (bool): If True, generates and saves batch-wise PDF grid plots.</p></li>
<li><p>overlay (bool): If True, overlays activation maps on input images.</p></li>
<li><p>correlation (bool): If True, computes activation correlation features (e.g., Manders’).</p></li>
</ul>
</dd>
<dt>Correlation-specific:</dt><dd><ul class="simple">
<li><p>manders_thresholds (list or float): Threshold(s) for calculating Manders’ coefficients.</p></li>
</ul>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p>PNG or JPEG activation maps organized by predicted class and well.</p></li>
<li><p>PDF files with batch-wise overlay plots if <cite>plot=True</cite>.</p></li>
<li><p>Activation image metadata and correlations saved to SQL database if <cite>save=True</cite>.</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None. The following outputs are saved</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="spacr.deep_spacr.visualize_classes">
<span class="sig-prename descclassname"><span class="pre">spacr.deep_spacr.</span></span><span class="sig-name descname"><span class="pre">visualize_classes</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">class_names</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/spacr/deep_spacr.html#visualize_classes"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#spacr.deep_spacr.visualize_classes" title="Link to this definition"></a></dt>
<dd><p>Visualize synthetic input images that maximize class activation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>torch.nn.Module</em>) – The trained classification model.</p></li>
<li><p><strong>dtype</strong> (<em>str</em>) – Data type or domain tag used for visualization.</p></li>
<li><p><strong>class_names</strong> (<em>list</em>) – List of class names (length 2 assumed for binary classification).</p></li>
<li><p><strong>**kwargs</strong> – Additional keyword arguments passed to <cite>class_visualization()</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>None. Displays matplotlib plots of class visualizations.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="spacr.deep_spacr.visualize_integrated_gradients">
<span class="sig-prename descclassname"><span class="pre">spacr.deep_spacr.</span></span><span class="sig-name descname"><span class="pre">visualize_integrated_gradients</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">src</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_label_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">image_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">224</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">channels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[1,</span> <span class="pre">2,</span> <span class="pre">3]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_integrated_grads</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_dir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'integrated_grads'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/spacr/deep_spacr.html#visualize_integrated_gradients"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#spacr.deep_spacr.visualize_integrated_gradients" title="Link to this definition"></a></dt>
<dd><p>Visualize integrated gradients for PNG images in a directory.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>src</strong> (<em>str</em>) – Directory containing <cite>.png</cite> images.</p></li>
<li><p><strong>model_path</strong> (<em>str</em>) – Path to the trained PyTorch model.</p></li>
<li><p><strong>target_label_idx</strong> (<em>int</em>) – Index of the target class label.</p></li>
<li><p><strong>image_size</strong> (<em>int</em>) – Image size after preprocessing (center crop).</p></li>
<li><p><strong>channels</strong> (<em>list</em>) – List of channels to extract (1-indexed).</p></li>
<li><p><strong>normalize</strong> (<em>bool</em>) – Whether to normalize image input to [-1, 1].</p></li>
<li><p><strong>save_integrated_grads</strong> (<em>bool</em>) – Whether to save integrated gradient maps.</p></li>
<li><p><strong>save_dir</strong> (<em>str</em>) – Directory to save integrated gradient outputs.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>None. Displays overlays and optionally saves saliency maps.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="spacr.deep_spacr.SmoothGrad">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">spacr.deep_spacr.</span></span><span class="sig-name descname"><span class="pre">SmoothGrad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">50</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stdev_spread</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.15</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/spacr/deep_spacr.html#SmoothGrad"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#spacr.deep_spacr.SmoothGrad" title="Link to this definition"></a></dt>
<dd><p>Compute SmoothGrad saliency maps from a trained model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>torch.nn.Module</em>) – Trained classification model.</p></li>
<li><p><strong>n_samples</strong> (<em>int</em>) – Number of noise samples to average.</p></li>
<li><p><strong>stdev_spread</strong> (<em>float</em>) – Standard deviation of noise relative to input range.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="spacr.deep_spacr.SmoothGrad.model">
<span class="sig-name descname"><span class="pre">model</span></span><a class="reference internal" href="../../../_modules/spacr/deep_spacr.html#SmoothGrad.model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#spacr.deep_spacr.SmoothGrad.model" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="spacr.deep_spacr.SmoothGrad.n_samples">
<span class="sig-name descname"><span class="pre">n_samples</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">50</span></em><a class="reference internal" href="../../../_modules/spacr/deep_spacr.html#SmoothGrad.n_samples"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#spacr.deep_spacr.SmoothGrad.n_samples" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="spacr.deep_spacr.SmoothGrad.stdev_spread">
<span class="sig-name descname"><span class="pre">stdev_spread</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0.15</span></em><a class="reference internal" href="../../../_modules/spacr/deep_spacr.html#SmoothGrad.stdev_spread"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#spacr.deep_spacr.SmoothGrad.stdev_spread" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="spacr.deep_spacr.SmoothGrad.compute_smooth_grad">
<span class="sig-name descname"><span class="pre">compute_smooth_grad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_class</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/spacr/deep_spacr.html#SmoothGrad.compute_smooth_grad"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#spacr.deep_spacr.SmoothGrad.compute_smooth_grad" title="Link to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="spacr.deep_spacr.visualize_smooth_grad">
<span class="sig-prename descclassname"><span class="pre">spacr.deep_spacr.</span></span><span class="sig-name descname"><span class="pre">visualize_smooth_grad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">src</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_label_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">image_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">224</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">channels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[1,</span> <span class="pre">2,</span> <span class="pre">3]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_smooth_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_dir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'smooth_grad'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/spacr/deep_spacr.html#visualize_smooth_grad"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#spacr.deep_spacr.visualize_smooth_grad" title="Link to this definition"></a></dt>
<dd><p>Visualize SmoothGrad maps for PNG images in a folder.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>src</strong> (<em>str</em>) – Path to directory containing <cite>.png</cite> images.</p></li>
<li><p><strong>model_path</strong> (<em>str</em>) – Path to trained PyTorch model file.</p></li>
<li><p><strong>target_label_idx</strong> (<em>int</em>) – Index of the class to explain.</p></li>
<li><p><strong>image_size</strong> (<em>int</em>) – Size for center cropping during preprocessing.</p></li>
<li><p><strong>channels</strong> (<em>list</em>) – Channel indices to extract from images.</p></li>
<li><p><strong>normalize</strong> (<em>bool</em>) – Whether to normalize inputs to [-1, 1].</p></li>
<li><p><strong>save_smooth_grad</strong> (<em>bool</em>) – If True, saves saliency maps to disk.</p></li>
<li><p><strong>save_dir</strong> (<em>str</em>) – Folder where smooth grad maps are saved.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>None. Displays overlay figures and optionally saves maps to disk.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="spacr.deep_spacr.deep_spacr">
<span class="sig-prename descclassname"><span class="pre">spacr.deep_spacr.</span></span><span class="sig-name descname"><span class="pre">deep_spacr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">settings</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/spacr/deep_spacr.html#deep_spacr"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#spacr.deep_spacr.deep_spacr" title="Link to this definition"></a></dt>
<dd><p>Run deep learning-based classification workflow on microscopy data using SpaCr.</p>
<p>This function handles dataset generation, model training, and inference using a trained model on tar-archived image datasets.
Settings are filled using <cite>deep_spacr_defaults</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>settings</strong> (<em>dict</em>) – <p>Dictionary of settings with the following keys:</p>
<dl class="simple">
<dt>General:</dt><dd><ul class="simple">
<li><p>src (str): Path to the input dataset.</p></li>
<li><p>dataset (str): Path to a dataset archive.</p></li>
<li><p>dataset_mode (str): Dataset generation mode. Typically ‘metadata’.</p></li>
<li><p>file_type (str): Type of input files (e.g., ‘cell_png’).</p></li>
<li><p>file_metadata (str or None): Path to file-level metadata, if available.</p></li>
<li><p>sample (int or None): Limit to N random samples for development/testing.</p></li>
<li><p>experiment (str): Experiment name prefix. Default is ‘exp.’.</p></li>
</ul>
</dd>
<dt>Annotation and class mapping:</dt><dd><ul class="simple">
<li><p>annotation_column (str): Metadata column containing class annotations.</p></li>
<li><p>annotated_classes (list): List of class IDs used for training (e.g., [1, 2]).</p></li>
<li><p>classes (list): Class labels (e.g., [‘nc’, ‘pc’]).</p></li>
<li><p>class_metadata (list of lists): Mapping of classes to metadata terms (e.g., [[‘c1’], [‘c2’]]).</p></li>
<li><p>metadata_type_by (str): How to interpret metadata structure. Typically ‘columnID’.</p></li>
</ul>
</dd>
<dt>Image processing:</dt><dd><ul class="simple">
<li><p>channel_of_interest (int): Channel index to use for classification.</p></li>
<li><p>png_type (str): Type of image format (e.g., ‘cell_png’).</p></li>
<li><p>image_size (int): Input size (e.g., 224 for 224x224 crop).</p></li>
<li><p>train_channels (list): Channels to use for training (e.g., [‘r’, ‘g’, ‘b’]).</p></li>
<li><p>normalize (bool): Whether to normalize input images. Default is True.</p></li>
<li><p>augment (bool): Whether to apply data augmentation.</p></li>
</ul>
</dd>
<dt>Model and training:</dt><dd><ul class="simple">
<li><p>model_type (str): Model architecture (e.g., ‘maxvit_t’).</p></li>
<li><p>optimizer_type (str): Optimizer (e.g., ‘adamw’).</p></li>
<li><p>schedule (str): Learning rate scheduler (‘reduce_lr_on_plateau’ or ‘step_lr’).</p></li>
<li><p>loss_type (str): Loss function (‘focal_loss’ or ‘binary_cross_entropy_with_logits’).</p></li>
<li><p>dropout_rate (float): Dropout probability.</p></li>
<li><p>init_weights (bool): Initialize model with pretrained weights.</p></li>
<li><p>amsgrad (bool): Use AMSGrad variant of AdamW optimizer.</p></li>
<li><p>use_checkpoint (bool): Enable checkpointing.</p></li>
<li><p>intermedeate_save (bool): Save intermediate models during training.</p></li>
</ul>
</dd>
<dt>Training control:</dt><dd><ul class="simple">
<li><p>train (bool): Enable training phase.</p></li>
<li><p>test (bool): Enable evaluation on test set.</p></li>
<li><p>train_DL_model (bool): Enable deep learning model training.</p></li>
<li><p>generate_training_dataset (bool): Enable generation of train/test splits.</p></li>
<li><p>test_split (float): Proportion of data used for testing.</p></li>
<li><p>val_split (float): Fraction of training set used for validation.</p></li>
<li><p>epochs (int): Number of training epochs.</p></li>
<li><p>batch_size (int): Batch size for training and inference.</p></li>
<li><p>learning_rate (float): Learning rate.</p></li>
<li><p>weight_decay (float): L2 regularization strength.</p></li>
<li><p>gradient_accumulation (bool): Accumulate gradients over multiple steps.</p></li>
<li><p>gradient_accumulation_steps (int): Number of steps per gradient update.</p></li>
</ul>
</dd>
<dt>Inference:</dt><dd><ul class="simple">
<li><p>apply_model_to_dataset (bool): Run prediction on tar dataset.</p></li>
<li><p>tar_path (str): Path to tar file for inference input.</p></li>
<li><p>model_path (str): Path to trained model file.</p></li>
<li><p>score_threshold (float): Probability threshold for binary classification.</p></li>
</ul>
</dd>
<dt>Execution:</dt><dd><ul class="simple">
<li><p>n_jobs (int): Number of parallel workers.</p></li>
<li><p>pin_memory (bool): Whether to use pinned memory in DataLoader.</p></li>
<li><p>verbose (bool): Print training and evaluation progress.</p></li>
</ul>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>None. All outputs (trained models, predictions, settings) are saved to disk.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="spacr.deep_spacr.model_knowledge_transfer">
<span class="sig-prename descclassname"><span class="pre">spacr.deep_spacr.</span></span><span class="sig-name descname"><span class="pre">model_knowledge_transfer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">teacher_paths</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">student_save_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_loader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">student_model_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'maxvit_t'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pretrained</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_checkpoint</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/spacr/deep_spacr.html#model_knowledge_transfer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#spacr.deep_spacr.model_knowledge_transfer" title="Link to this definition"></a></dt>
<dd><p>Perform knowledge distillation from one or more teacher models to a student model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>teacher_paths</strong> (<em>list</em><em> of </em><em>str</em>) – Paths to pretrained teacher model files (.pth).</p></li>
<li><p><strong>student_save_path</strong> (<em>str</em>) – Output path for the saved student model.</p></li>
<li><p><strong>data_loader</strong> (<em>torch.utils.data.DataLoader</em>) – DataLoader for training data.</p></li>
<li><p><strong>device</strong> (<em>str</em>) – Device to use (‘cpu’ or ‘cuda’).</p></li>
<li><p><strong>student_model_name</strong> (<em>str</em>) – Name of the student model architecture (e.g., ‘maxvit_t’).</p></li>
<li><p><strong>pretrained</strong> (<em>bool</em>) – Whether to initialize the student model with ImageNet weights.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em><em> or </em><em>None</em>) – Dropout rate for the student model.</p></li>
<li><p><strong>use_checkpoint</strong> (<em>bool</em>) – Whether to use gradient checkpointing.</p></li>
<li><p><strong>alpha</strong> (<em>float</em>) – Weighting factor between cross-entropy and distillation loss.</p></li>
<li><p><strong>temperature</strong> (<em>float</em>) – Temperature scaling for soft targets.</p></li>
<li><p><strong>lr</strong> (<em>float</em>) – Learning rate for optimizer.</p></li>
<li><p><strong>epochs</strong> (<em>int</em>) – Number of training epochs.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The trained student model after knowledge distillation.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../utils/index.html#spacr.utils.TorchModel" title="spacr.utils.TorchModel">TorchModel</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="spacr.deep_spacr.model_fusion">
<span class="sig-prename descclassname"><span class="pre">spacr.deep_spacr.</span></span><span class="sig-name descname"><span class="pre">model_fusion</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_paths</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'maxvit_t'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pretrained</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_checkpoint</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggregator</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mean'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/spacr/deep_spacr.html#model_fusion"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#spacr.deep_spacr.model_fusion" title="Link to this definition"></a></dt>
<dd><p>Fuse multiple trained models by combining their parameters using a specified aggregation method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_paths</strong> (<em>list</em><em> of </em><em>str</em>) – List of paths to model checkpoints to be fused.</p></li>
<li><p><strong>save_path</strong> (<em>str</em>) – Path where the fused model will be saved.</p></li>
<li><p><strong>device</strong> (<em>str</em>) – Device to use (‘cpu’ or ‘cuda’).</p></li>
<li><p><strong>model_name</strong> (<em>str</em>) – Model architecture to use when initializing.</p></li>
<li><p><strong>pretrained</strong> (<em>bool</em>) – Whether to initialize with pretrained weights.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em><em> or </em><em>None</em>) – Dropout rate to apply to the model.</p></li>
<li><p><strong>use_checkpoint</strong> (<em>bool</em>) – Whether to use gradient checkpointing.</p></li>
<li><p><strong>aggregator</strong> (<em>str</em>) – Aggregation strategy to combine weights. One of {‘mean’, ‘geomean’, ‘median’, ‘sum’, ‘max’, ‘min’}.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The fused model with combined weights.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../utils/index.html#spacr.utils.TorchModel" title="spacr.utils.TorchModel">TorchModel</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="spacr.deep_spacr.annotate_filter_vision">
<span class="sig-prename descclassname"><span class="pre">spacr.deep_spacr.</span></span><span class="sig-name descname"><span class="pre">annotate_filter_vision</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">settings</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/spacr/deep_spacr.html#annotate_filter_vision"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#spacr.deep_spacr.annotate_filter_vision" title="Link to this definition"></a></dt>
<dd><p>Annotate and filter a CSV file with experimental metadata and optionally remove training samples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>settings</strong> (<em>dict</em>) – Configuration dictionary with keys:
- ‘src’ (str or list): Paths to CSV annotation files.
- ‘cells’ (dict): Mapping of cell types to annotation labels.
- ‘cell_loc’ (str): Column name for cell type annotations.
- ‘pathogens’ (dict): Mapping of pathogens to annotation labels.
- ‘pathogen_loc’ (str): Column name for pathogen annotations.
- ‘treatments’ (dict): Mapping of treatments to annotation labels.
- ‘treatment_loc’ (str): Column name for treatment annotations.
- ‘filter_column’ (str or None): Column to filter on.
- ‘upper_threshold’ (float): Upper bound for filtering.
- ‘lower_threshold’ (float): Lower bound for filtering.
- ‘remove_train’ (bool): If True, removes rows present in training folders.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>None. Saves filtered and annotated CSVs to disk.</p>
</dd>
</dl>
</dd></dl>

</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>