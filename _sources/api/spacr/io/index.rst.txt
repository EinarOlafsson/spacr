spacr.io
========

.. py:module:: spacr.io






Module Contents
---------------

.. py:function:: process_non_tif_non_2D_images(folder)

   Processes all images in the folder and splits them into grayscale channels, preserving bit depth.


.. py:class:: CombineLoaders(train_loaders)

   A class that combines multiple data loaders into a single iterator.

   Args:
       train_loaders (list): A list of data loaders.

   Attributes:
       train_loaders (list): A list of data loaders.
       loader_iters (list): A list of iterator objects for each data loader.

   Methods:
       __iter__(): Returns the iterator object itself.
       __next__(): Returns the next batch from one of the data loaders.

   Raises:
       StopIteration: If all data loaders have been exhausted.



   .. py:attribute:: train_loaders


   .. py:attribute:: loader_iters


.. py:class:: CombinedDataset(datasets, shuffle=True)

   Bases: :py:obj:`torch.utils.data.Dataset`


   A dataset that combines multiple datasets into one.

   Args:
       datasets (list): A list of datasets to be combined.
       shuffle (bool, optional): Whether to shuffle the combined dataset. Defaults to True.


   .. py:attribute:: datasets


   .. py:attribute:: lengths


   .. py:attribute:: total_length


   .. py:attribute:: shuffle
      :value: True



.. py:class:: NoClassDataset(data_dir, transform=None, shuffle=True, load_to_memory=False)

   Bases: :py:obj:`torch.utils.data.Dataset`


   A custom dataset class for handling image data without class labels.

   Args:
       data_dir (str): The directory path where the image files are located.
       transform (callable, optional): A function/transform to apply to the image data. Default is None.
       shuffle (bool, optional): Whether to shuffle the dataset. Default is True.
       load_to_memory (bool, optional): Whether to load all images into memory. Default is False.

   Attributes:
       data_dir (str): The directory path where the image files are located.
       transform (callable): A function/transform to apply to the image data.
       shuffle (bool): Whether to shuffle the dataset.
       load_to_memory (bool): Whether to load all images into memory.
       filenames (list): A list of file paths for the image files.
       images (list): A list of loaded images (if load_to_memory is True).


   .. py:attribute:: data_dir


   .. py:attribute:: transform
      :value: None



   .. py:attribute:: shuffle
      :value: True



   .. py:attribute:: load_to_memory
      :value: False



   .. py:attribute:: filenames


   .. py:method:: load_image(img_path)

      Load an image from the given file path.

      Args:
          img_path (str): The file path of the image.

      Returns:
          PIL.Image: The loaded image.



   .. py:method:: shuffle_dataset()

      Shuffle the dataset.



.. py:class:: spacrDataset(data_dir, loader_classes, transform=None, shuffle=True, pin_memory=False, specific_files=None, specific_labels=None)

   Bases: :py:obj:`torch.utils.data.Dataset`


   .. py:attribute:: data_dir


   .. py:attribute:: classes


   .. py:attribute:: transform
      :value: None



   .. py:attribute:: shuffle
      :value: True



   .. py:attribute:: pin_memory
      :value: False



   .. py:attribute:: filenames
      :value: []



   .. py:attribute:: labels
      :value: []



   .. py:method:: load_image(img_path)


   .. py:method:: shuffle_dataset()


   .. py:method:: get_plate(filepath)


.. py:class:: spacrDataLoader(*args, preload_batches=1, **kwargs)

   Bases: :py:obj:`torch.utils.data.DataLoader`


   .. py:attribute:: preload_batches
      :value: 1



   .. py:attribute:: batch_queue


   .. py:attribute:: process
      :value: None



   .. py:attribute:: current_batch_index
      :value: 0



   .. py:attribute:: pin_memory


   .. py:method:: cleanup()


.. py:class:: NoClassDataset(data_dir, transform=None, shuffle=True, load_to_memory=False)

   Bases: :py:obj:`torch.utils.data.Dataset`


   .. py:attribute:: data_dir


   .. py:attribute:: transform
      :value: None



   .. py:attribute:: shuffle
      :value: True



   .. py:attribute:: load_to_memory
      :value: False



   .. py:attribute:: filenames


   .. py:method:: load_image(img_path)


   .. py:method:: shuffle_dataset()


.. py:class:: TarImageDataset(tar_path, transform=None)

   Bases: :py:obj:`torch.utils.data.Dataset`


   .. py:attribute:: tar_path


   .. py:attribute:: transform
      :value: None



.. py:function:: load_images_from_paths(images_by_key)

.. py:function:: concatenate_and_normalize(src, channels, save_dtype=np.float32, settings={})

.. py:function:: delete_empty_subdirectories(folder_path)

   Deletes all empty subdirectories in the specified folder.

   Args:
   - folder_path (str): The path to the folder in which to look for empty subdirectories.


.. py:function:: preprocess_img_data(settings)

.. py:function:: read_plot_model_stats(train_file_path, val_file_path, save=False)

.. py:function:: convert_numpy_to_tiff(folder_path, limit=None)

   Converts all numpy files in a folder to TIFF format and saves them in a subdirectory 'tiff'.

   Args:
   folder_path (str): The path to the folder containing numpy files.


.. py:function:: generate_cellpose_train_test(src, test_split=0.1)

.. py:function:: parse_gz_files(folder_path)

   Parses the .fastq.gz files in the specified folder path and returns a dictionary
   containing the sample names and their corresponding file paths.

   Args:
       folder_path (str): The path to the folder containing the .fastq.gz files.

   Returns:
       dict: A dictionary where the keys are the sample names and the values are
       dictionaries containing the file paths for the 'R1' and 'R2' read directions.


.. py:function:: generate_dataset(settings={})

.. py:function:: generate_loaders(src, mode='train', image_size=224, batch_size=32, classes=['nc', 'pc'], n_jobs=None, validation_split=0.0, pin_memory=False, normalize=False, channels=[1, 2, 3], augment=False, verbose=False)

   Generate data loaders for training and validation/test datasets.

   Parameters:
   - src (str): The source directory containing the data.
   - mode (str): The mode of operation. Options are 'train' or 'test'.
   - image_size (int): The size of the input images.
   - batch_size (int): The batch size for the data loaders.
   - classes (list): The list of classes to consider.
   - n_jobs (int): The number of worker threads for data loading.
   - validation_split (float): The fraction of data to use for validation.
   - pin_memory (bool): Whether to pin memory for faster data transfer.
   - normalize (bool): Whether to normalize the input images.
   - verbose (bool): Whether to print additional information and show images.
   - channels (list): The list of channels to retain. Options are [1, 2, 3] for all channels, [1, 2] for blue and green, etc.

   Returns:
   - train_loaders (list): List of data loaders for training datasets.
   - val_loaders (list): List of data loaders for validation datasets.


.. py:function:: generate_training_dataset(settings)

.. py:function:: training_dataset_from_annotation(db_path, dst, annotation_column='test', annotated_classes=(1, 2))

.. py:function:: training_dataset_from_annotation_metadata(db_path, dst, annotation_column='test', annotated_classes=(1, 2), metadata_type_by='columnID', class_metadata=['c1', 'c2'])

.. py:function:: generate_dataset_from_lists(dst, class_data, classes, test_split=0.1)

.. py:function:: convert_separate_files_to_yokogawa(folder, regex)

.. py:function:: convert_to_yokogawa(folder)

   Detects file type in the folder and converts them
   to Yokogawa-style naming with Maximum Intensity Projection (MIP).


.. py:function:: apply_augmentation(image, method)

.. py:function:: process_instruction(entry)

.. py:function:: prepare_cellpose_dataset(input_root, augment_data=False, train_fraction=0.8, n_jobs=None)

