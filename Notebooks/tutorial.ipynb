{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae82f9ad-f0d1-479a-a227-d38d483784fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacr.core import preprocess_generate_masks\n",
    "%matplotlib inline\n",
    "\n",
    "settings = {'src':'path', # (path) path to source folder (where origional images were stored)\n",
    "            'metadata_type':'cellvoyager', # (string) - type of fime name metadata (cellvoyager, cq1, Nikon)\n",
    "            'custom_regex':None, # (regex) - Regular expression if filename metadata not in metadata_type \n",
    "            'experiment':'screen', # (string) - Name of experiment\n",
    "            'channels':[0,1,2,3], # (list) - list of integers representing available channels\n",
    "            'cell_channel':3, # (integer or NoneType) - Cell image dimension \n",
    "            'cell_background':100, # (integer) - Background value in cell images\n",
    "            'cell_Signal_to_noise':10, # (integer) - Signal to noise ration for cell channel\n",
    "            'cell_CP_prob':-1, # (integer) - Cellpose Cell probability\n",
    "            'remove_background_cell':False, # (bool) - Set background to 0 for cell channel\n",
    "            'nucleus_channel':0, # (Optional, integer or NoneType) - Nucleus image dimension \n",
    "            'nucleus_background':200, # (Optional, integer) - Background value in nucleus images\n",
    "            'nucleus_Signal_to_noise':5, # (Optional, integer) - Signal to noise ration for nucleus channel\n",
    "            'nucleus_CP_prob':0, # (Optional, integer) - Cellpose Nucleus probability\n",
    "            'remove_background_nucleus':False, # (Optional, bool) - Set background to 0 for nucleus channel\n",
    "            'pathogen_model':None, # (Optional, path or NoneType) - Custom cellpose model path for pathogen detection\n",
    "            'pathogen_channel':2, # (Optional, integer or NoneType) - Pathogen image dimension \n",
    "            'pathogen_background':150, # (Optional, integer) - Background value in pathogen images\n",
    "            'pathogen_Signal_to_noise':6, # (Optional, integer) - Signal to noise ration for pathogen channel\n",
    "            'pathogen_CP_prob':-2, # (Optional, integer) - Cellpose pathogen probability\n",
    "            'remove_background_pathogen':True, # (Optional, bool) - Set background to 0 for pathogen channel\n",
    "            'consolidate':False, \n",
    "            'magnification':20, # (integer) - Objective magnefication used to aquire images (40, 60, 100)\n",
    "            'save':True, # (bool) - Save masks and object data to database\n",
    "            'preprocess':True, # (bool) - Preprocess images\n",
    "            'masks':True, # (bool) - Generate masks\n",
    "            'batch_size':100, # (bool) - Number of images to be normalized together and loaded onto the GPU\n",
    "            'filter':False, # (bool) - Filter objects based on size\n",
    "            'merge_pathogens':False, # (bool) - Merge pathogens that share > 75% perimiter\n",
    "            'plot':False, # (bool) - Plot normalized intensity and object images\n",
    "            'adjust_cells':True, # (bool) - If cell, nucleus and pathogen: merge cells that share a pathogen\n",
    "            'test_mode':False, # (bool) - Test settings in test mode before analyzing entire experiment\n",
    "            'test_images':100, # (integer) - Number of images to analyze in test mode\n",
    "            'random_test':True} # (bool) - Randomize images for test mode\n",
    "\n",
    "preprocess_generate_masks(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bf02d1-9f7c-4ac2-82d6-68b3a66d19dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacr.measure import measure_crop\n",
    "%matplotlib inline\n",
    "\n",
    "settings = {'src':'path', # (path) path to source folder (ens in /merged)\n",
    "            'channels':[0,1,2,3],# (list) - list of integers representing available channels\n",
    "            'cell_mask_dim':4, # (integer or NoneType) - Cell mask dimension \n",
    "            'cell_min_size':2000, # (integer) - minimum size in px2 of cell objects\n",
    "            'nucleus_mask_dim':5, # (integer or NoneType) - Nucleus mask dimension \n",
    "            'nucleus_min_size':1000, # (integer) - minimum size in px2 of nuclei objects\n",
    "            'pathogen_mask_dim':6, # (integer or NoneType) - Pathogen mask dimension \n",
    "            'pathogen_min_size':400, # (integer) - minimum size in px2 of pathogen objects\n",
    "            'cytoplasm_min_size':0, # (integer) - minimum size in px2 of cutoplasm (cell-(nucleus+pathogen)) objects\n",
    "            'save_png':True, # (bool) - save objects as PNGs\n",
    "            'crop_mode':['cell'], # (list) - Object(s) to be cropped into images ('cell', 'nuclei', 'pathogen')\n",
    "            'use_bounding_box':False, # (bool) - Use bounding box for cropped images instead of object area\n",
    "            'png_size':[[224,224]], # (list of lists) - size of single object pngs\n",
    "            'normalize':False, # (bool or list) - normalize PNGs to percentiles\n",
    "            'png_dims':[0,1,2], # (list) - Dimensions to include in PNG images\n",
    "            'normalize_by':'png', # (string) - If normalize, normalize to fov (field of view) or png \n",
    "            'save_measurements':True, # (bool) - Save measurements\n",
    "            'plot':False, # (bool) - plot images during analazys\n",
    "            'plot_filtration':False, # (bool) - Plot filtration steps\n",
    "            'uninfected':False, # () - Include uninfected\n",
    "            'test_mode':False, # (bool) - Activate Test mode\n",
    "            'test_nr':10} # (integer) - Number of images to analyze in test mode\n",
    "\n",
    "measure_crop(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38090c27-49d5-44ee-835a-ae5e04dc9194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description: Train a ML model to classigy cells based on measurement data\n",
    "from spacr.ml import generate_ml_scores\n",
    "%matplotlib inline\n",
    "\n",
    "settings = {'src':'path', # (path) path to source folder (where origional images were stored)\n",
    "            'model_type_ml':'xgboost', # (string) - Type of model ( 'random_forest', 'xgboost', 'gradient_boosting')\n",
    "            'heatmap_feature':'predictions', # (string) - column to display in heatmaps\n",
    "            'grouping':'mean', # (string) - Grouping for heatmap\n",
    "            'min_max':'allq', # (string) - Quantiles to normalize heatmap to (all, allq)\n",
    "            'cmap':'viridis', # (string) - Heatmap cmap\n",
    "            'n_estimators':100, # (integer) - Number of estimators for model\n",
    "            'test_size':0.2, # (float) - Fraction of images used for the test set\n",
    "            'location_column':'column_name', # (string) - Column containing negative/ positive controll metadata information.\n",
    "            'positive_control':'c2', # (string) - Value for positive control in location column\n",
    "            'negative_control':'c1', # (string) - Value for negative control in location column\n",
    "            'exclude':None, # (string, NoneType) - Rows to exclude in location_column\n",
    "            'nuclei_limit':1, # (integer) - Maximum number of nuclei for each cell\n",
    "            'pathogen_limit':3, # (integer) - Maximum number of pathogens per cell\n",
    "            'n_repeats':10, # (integer) - Number of repeats for permutation importance.\n",
    "            'top_features':30, # (integer) - Number of top features to plot based on permutation importance, feature importance and shap.\n",
    "            'channel_of_interest':1, # (integer) - \n",
    "            'minimum_cell_count':25, # (integer) - Minimum number of cells per well\n",
    "            'remove_low_variance_features':True, # (bool) - Remove columns with low variance.\n",
    "            'remove_highly_correlated_features':True, # (bool) - Remove highly correlated features.\n",
    "            'verbose':False, # (bool) - Display verbose output\n",
    "            'n_jobs':10} # (integer) - Number of threads\n",
    "\n",
    "results = generate_ml_scores(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4dde9e-2046-4327-975e-d08dd7455a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description: Fit a regression model to estimate the effect size of gRNAs on cell scores.\n",
    "from spacr.ml import perform_regression\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "settings = {'count_data':'path', # (path) path or list of paths to sequencing count data\n",
    "            'score_data':'path', # (path) path or list of paths to score data\n",
    "            'score_column':'column', # () - column with cell scores\n",
    "            'metadata_files':['path.csv','path.csv'], # (list) pahts to gene metadata \n",
    "            'positive_control':'gene', # (string) - gene to highlight in volcano plot\n",
    "            'negative_control':'gene', # (string) - gene to highlight in volcano plot\n",
    "            'min_n':3, # () - \n",
    "            'fraction_threshold':None, # (Optional, float or NoneType) - Minimum threshold for gene fraction, if None automatically calculated\n",
    "            'target_unique_count':5, # () - Number of expected unique gRNAs per well\n",
    "            'tolerance':0.02, # (float) - Tollerance for cells per well limit\n",
    "            'log_x':False, # () - gRNA Fraction plot X axis log\n",
    "            'log_y':False, # () - gRNA Fraction plot Y axis log\n",
    "            'x_lim':None, # () - Volcano X axis limit\n",
    "            'control_wells':['c1','c2','c3'], # (list) - Metadata to exclude from regression model\n",
    "            'filter_column':'column', # (str) - Column containing control metadata to remove\n",
    "            'dependent_variable': 'column', # (string) - Dependent variable for regression\n",
    "            'threshold_method':'var', # (string) - effect size thresold type (std or var)\n",
    "            'threshold_multiplier':4, # (integer) - effect size threshold multiplyer \n",
    "            'transform':'log', # (string) - Transform dependent variable\n",
    "            'agg_type':'mean', # (string) - aggregation for dependent variable\n",
    "            'min_cell_count':None, # (integer) - Minimum number of cells per well\n",
    "            'regression_type':'ols', # (string) - Type of regression (ols, glm, mixed, ridge, lasso).\n",
    "            'random_row_column_effects':False, # (bool) - Remove plate , row and column random effects.\n",
    "            'y_lims':[[0,9], [12, 16]], # (list of lists) limits for broken y axis\n",
    "            'plate':None, # (string or NoneType) - strinf to replace plate column values with\n",
    "            'cov_type':None, # (string) - covariance type for ols regression\n",
    "            'volcano':'gene', # (string) - mode for significant resuls (gene, grna, all)\n",
    "            'alpha':0.8} # (float) - alpha for hinge and lasso regression\n",
    "\n",
    "coef_df = perform_regression(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7a8b5b-93f2-4b5c-884d-b4cc62fa0c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description: use this cell to generate train and test folders: datasets/train/nc and pc and datasets/test/nc and pc\n",
    "from spacr.io import generate_training_dataset\n",
    "\n",
    "settings = {'src':'path', # (path) path to source folder (where origional images were stored)\n",
    "            'dataset_mode':'metadata_annotation', # (string) annotation, measurement, metadata, annotation_metadata\n",
    "            'tables':['cell'],# (list of strings) The tabels present in the database, excluding png_list\n",
    "            'test_split':0.1, # (float) Fraction of images used for the test set\n",
    "            'annotation_column':'test', # (Optional, string) If using mode annotation, The annotation column in the database\n",
    "            'annotated_classes':[1], # (Optional, list of integers) If using mode annotation, The interger in annotation_column, if len(annotated_classes) is 1, class 2 will be generated from a random selection of images.\n",
    "            'metadata_type_by':'column_name', # (Optional, strin) If using mode medatada, If using mode medatada,the column class_metadata elements are in\n",
    "            'class_metadata':['c10','c11','c12','c22','c23','c24'], # (Optional, list of lists of strings) If using mode medatada, the elements that deffine each class \n",
    "            'png_type':'cell_png', # (Optional, string) string in the path of each image (used to filter images)\n",
    "            'nuclei_limit':False, # (Optional, bool) if cell and nucleus in tables, filter for number of nuclei per cell\n",
    "            'pathogen_limit':0, # (Optional, integer) if cell and pathogen in tables, filter for number of pathogen per cell\n",
    "            'uninfected':True, # (Optional, bool) if cell and pathogen in tables, bool for uninfected cells (cells)\n",
    "            'size':None # (Optional, integer or NoneType) limit for number of images to include in total (test + train) per class\n",
    "           }\n",
    "\n",
    "generate_training_dataset(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9130db-61b5-4d0c-8c47-74c2834f298b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description: train a torch model\n",
    "from spacr.deep_spacr import train_test_model\n",
    "\n",
    "settings = {'src':'path', # (path) path to source folder (ends with datasets/training)\n",
    "            'train':False, # (bool) - Train\n",
    "            'test': True, # (bool) - Test\n",
    "            'custom_model':'path', # (path) - path to a custom model\n",
    "            'classes':['nc','pc'], # (list) - list of classes (folder names in dataset/training/train or test)\n",
    "            'model_type':'maxvit_t', # (string) - Name of torch model architecture\n",
    "            'optimizer_type':'adamw', # (string) - type of optimizer\n",
    "            'schedule':'reduce_lr_on_plateau', # (string) - type of scheduler (reduce_lr_on_plateau or step_lr)\n",
    "            'loss_type':'focal_loss', # (string) - Loss function (binary_cross_entropy_with_logits or focal_loss)\n",
    "            'normalize':True, # (bool) - Apply ImageNet normalization to images before training.\n",
    "            'image_size':224, # (int) - Size of images, height and width.\n",
    "            'batch_size':64, # (int) - Nr. of images per batch\n",
    "            'epochs':100, # (int) - Nr. of epochs for training\n",
    "            'val_split':0.1, # (float) - Fraction of images in validation dataset\n",
    "            'learning_rate':0.0001, # (float) - Learning rate per epoch\n",
    "            'weight_decay':0.00001, # (float) - Fraction of random weights decay (regularization)\n",
    "            'dropout_rate':0.1, # (float) - Fraction of weights to omit per epoch (regularization)\n",
    "            'init_weights':True, # (bool) - Initiate model with ImageNet weights\n",
    "            'amsgrad':True, # (bool) - guard against exploding gradients\n",
    "            'use_checkpoint':True, # (bool) - checkpoint gradient calculations to save VRAM at the expence of computation\n",
    "            'gradient_accumulation':True, # (bool) - Accumulate gradients to mimic larger batches\n",
    "            'gradient_accumulation_steps':4, # (int) - Epochs to accumulate gradients\n",
    "            'intermedeate_save':True, # Save intermediate states of the model\n",
    "            'pin_memory':True, # (bool) - Whether to pin memory for the data loader\n",
    "            'n_jobs':30, # (int) - Number of threads to use\n",
    "            'train_channels':['r','g','b'], # (list of 'r', 'g', and/or 'b') - PNG channels to use for training\n",
    "            'augment':False, # (bool) - Augment the dataset, vertical, horizontal flip and rotate each image to artificially expand the dataset 8 fold.\n",
    "            'verbose':True}\n",
    "\n",
    "train_test_model(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e899cd7-eb9e-49ad-a612-5ae95283fef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description: generate a tar dataset\n",
    "from spacr.io import generate_dataset\n",
    "\n",
    "settings = {'src':'path', # (path) path to source folder (where origional images were stored)\n",
    "           'file_metadata':'cell_png', # (Optional, string) string in the path of each image (used to filter images)\n",
    "           'experiment':'test', # (string) - Name of dataset\n",
    "           'sample':10000} # (Optional, integer or NoneType) limit for number of images to include in the dataset\n",
    "\n",
    "generate_dataset(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a71df0a-9bba-48ad-a45d-4b3df6daae95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description: apply a model to a tar dataset\n",
    "from spacr.deep_spacr import apply_model_to_tar\n",
    "\n",
    "settings = {'dataset':'path.tar', # (path) - path to tar dataset (ends with .tar) \n",
    "            'model_path':'path.pth', # (path) - path to model (ends with .pth) \n",
    "            'file_type':'cell_png', # (Optional, string) string in the path of each image (used to filter images)\n",
    "            'image_size':224, # (int) - Size of images, height and width\n",
    "            'batch_size':64, # (int) - Nr. of images per batch\n",
    "            'normalize':True, # (bool) - Apply ImageNet normalization to images before training.\n",
    "            'score_threshold':0.5, # (float) - Score to byass the classes\n",
    "            'n_jobs':30, # (int) - Number of threads to use\n",
    "            'verbose':True}\n",
    "\n",
    "result_df = apply_model_to_tar(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac9ba41-3a84-45a4-b7f5-ab5845fdbdd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0fb45d-805e-4059-a4b1-29eb29483a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacr.sequencing import generate_barecode_mapping\n",
    "\n",
    "settings = {'src': 'path',\n",
    "            'regex': '^(?P<column>.{8})TGCTG.*TAAAC(?P<grna>.{20,21})AACTT.*AGAAG(?P<row_name>.{8}).*',\n",
    "            'target_sequence': 'TGCTGTTTCCAGCATAGCTCTTAAAC',\n",
    "            'offset_start': -8,\n",
    "            'expected_end': 89,\n",
    "            'column_csv': 'path to column_barecodes.csv',\n",
    "            'grna_csv': 'path to grna_barcodes_RC.csv',\n",
    "            'row_csv': 'path to row_barecodes_RC.csv',\n",
    "            'save_h5': True,\n",
    "            'comp_type': 'zlib',\n",
    "            'comp_level': 5,\n",
    "            'chunk_size': 10000,\n",
    "            'n_jobs': None,\n",
    "            'mode': 'paired',\n",
    "            'single_direction': 'R1',\n",
    "            'test': False,\n",
    "            'fill_na':True}\n",
    "\n",
    "generate_barecode_mapping(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab28cd99-0395-4137-8b63-f3fe56611035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate cellpose dataset\n",
    "from spacr.io import prepare_cellpose_dataset\n",
    "\n",
    "input_root = 'path'\n",
    "\n",
    "prepare_cellpose_dataset(input_root, augment_data=True, train_fraction=0.8, n_jobs=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be26e4e1-6ec4-4d44-bcc3-70d5f942d44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train cellpose model\n",
    "from spacr.submodules import train_cellpose\n",
    "%matplotlib inline\n",
    "\n",
    "settings = {'src':'path',\n",
    "            'test':False,\n",
    "            'normalize':False,\n",
    "            'percentiles':None,\n",
    "            'invert':False,\n",
    "            'grayscale':True,\n",
    "            'rescale':False,\n",
    "            'circular':False,\n",
    "            'channels':[0,0],\n",
    "            'model_name':'test',\n",
    "            'model_type':'cyto',\n",
    "            'Signal_to_noise':10,\n",
    "            'background':200,\n",
    "            'remove_background':False,\n",
    "            'learning_rate':0.2,\n",
    "            'weight_decay':1e-05,\n",
    "            'batch_size':8,\n",
    "            'n_epochs':25000,\n",
    "            'from_scratch':False,\n",
    "            'diameter':30,\n",
    "            'resize':False,\n",
    "            'target_dimensions':1000,\n",
    "            'verbose':True}\n",
    "\n",
    "train_cellpose(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223b0906-b8ab-47e6-90a0-112aeef8f011",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacr",
   "language": "python",
   "name": "spacr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
