{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b370394d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Description: Generate train and test folders with class subfolders for training DL models.\n",
    "from spacr.io import generate_training_dataset\n",
    "\n",
    "settings = {'src':'path or list of paths',\n",
    "            'dataset_mode':'metadata',\n",
    "            'test_split':0.1,\n",
    "            'metadata_type_by':'col',\n",
    "            'class_metadata':[['c1'],['c2']],\n",
    "            'png_type':'cell_png',\n",
    "            'nuclei_limit':True,\n",
    "            'pathogen_limit':3,\n",
    "            'uninfected':False,\n",
    "            'size':None}\n",
    "\n",
    "generate_training_dataset(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb293108",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Description: Train a torch model to classify single object images\n",
    "from spacr.deep_spacr import train_test_model\n",
    "\n",
    "settings = {'src':'path', \n",
    "            'train':True,\n",
    "            'test': False,\n",
    "            'custom_model':False,\n",
    "            'custom_model_path':None,\n",
    "            'classes':['nc','pc'],\n",
    "            'model_type':'maxvit_t',\n",
    "            'optimizer_type':'adamw',\n",
    "            'schedule':'reduce_lr_on_plateau', #reduce_lr_on_plateau, step_lr\n",
    "            'loss_type':'focal_loss', #binary_cross_entropy_with_logits, #focal_loss\n",
    "            'normalize':True,\n",
    "            'image_size':224,\n",
    "            'batch_size':64,\n",
    "            'epochs':100,\n",
    "            'val_split':0.1,\n",
    "            'learning_rate':0.0001,\n",
    "            'weight_decay':0.00001,\n",
    "            'dropout_rate':0.1,\n",
    "            'init_weights':True,\n",
    "            'amsgrad':True,\n",
    "            'use_checkpoint':True,\n",
    "            'gradient_accumulation':True,\n",
    "            'gradient_accumulation_steps':4,\n",
    "            'intermedeate_save':True,\n",
    "            'pin_memory':True,\n",
    "            'n_jobs':30,\n",
    "            'train_channels':['r','g','b'],\n",
    "            'augment':False,\n",
    "            'verbose':True}\n",
    "\n",
    "train_test_model(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09107d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description: Generate a tar file containing single object images.\n",
    "from spacr.io import generate_dataset\n",
    "\n",
    "settings = {'src':'path or list of paths',\n",
    "           'file_metadata':None,\n",
    "           'experiment':'tsg101_screen_plate1',\n",
    "           'sample':None}\n",
    "\n",
    "generate_dataset(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52af6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description: Classify images in a tar dataset with a trained torch model.\n",
    "from spacr.core import apply_model_to_tar\n",
    "\n",
    "settings = {'tar_path':'path',\n",
    "            'model_path':'path', \n",
    "            'file_type':'cell_png',\n",
    "            'image_size':224,\n",
    "            'batch_size':64,\n",
    "            'normalize':True,\n",
    "            'score_threshold':0.5,\n",
    "            'n_jobs':30,\n",
    "            'verbose':True}\n",
    "\n",
    "result_df = spacr.core.apply_model_to_tar(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b36a8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description: Fix a regression model to estimate the effect size of gRNAs on cell scores.\n",
    "# \n",
    "\n",
    "from spacr.ml import perform_regression\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "settings = {'count_data':'path',\n",
    "            'score_data':'path',\n",
    "            'highlight':'string',\n",
    "            'fraction_threshold':0.1,\n",
    "            'dependent_variable': 'prediction_probability_class_1',\n",
    "            'transform':'log',\n",
    "            'agg_type':'median',\n",
    "            'min_cell_count':25,\n",
    "            'regression_type':'ols',\n",
    "            'random_row_column_effects':False,\n",
    "            'plate':None,\n",
    "            'cov_type':None,\n",
    "            'alpha':0.8,\n",
    "            'nc':'c1',\n",
    "            'pc':'c2',\n",
    "            'other':'c3'}\n",
    "\n",
    "coef_df = perform_regression(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d127863",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def model_fusion(model_paths, save_path, model_class, device='cpu'):\n",
    "    \"\"\"\n",
    "    Fuses an arbitrary number of models by averaging their weights and saves the fused model.\n",
    "\n",
    "    Parameters:\n",
    "        model_paths (list): List of file paths to the models to be fused (e.g., PyTorch .pth files).\n",
    "        save_path (str): File path to save the fused model.\n",
    "        model_class (class): The class of the model (e.g., your MaxViT class).\n",
    "        device (str): Device to load the models onto ('cpu' or 'cuda').\n",
    "\n",
    "    Returns:\n",
    "        fused_model: The fused model with averaged weights.\n",
    "    \"\"\"\n",
    "    # Initialize a list to hold the state dictionaries\n",
    "    state_dicts = []\n",
    "\n",
    "    # Load all model weights\n",
    "    for path in model_paths:\n",
    "        print(f\"Loading model from: {path}\")\n",
    "        state_dict = torch.load(path, map_location=device)\n",
    "        state_dicts.append(state_dict)\n",
    "\n",
    "    # Ensure all models have the same architecture\n",
    "    if not all(state_dicts[0].keys() == sd.keys() for sd in state_dicts):\n",
    "        raise ValueError(\"All models must have the same architecture and state_dict keys.\")\n",
    "\n",
    "    # Initialize a new model to hold the averaged weights\n",
    "    fused_model = model_class().to(device)\n",
    "    fused_state_dict = fused_model.state_dict()\n",
    "\n",
    "    # Iterate over all keys in the state dict and average the weights\n",
    "    for key in fused_state_dict.keys():\n",
    "        # Average the weights for this key across all models\n",
    "        fused_state_dict[key] = torch.stack([sd[key].float() for sd in state_dicts]).mean(dim=0)\n",
    "\n",
    "    # Load the averaged weights into the fused model\n",
    "    fused_model.load_state_dict(fused_state_dict)\n",
    "\n",
    "    # Save the fused model\n",
    "    torch.save(fused_model.state_dict(), save_path)\n",
    "    print(f\"Fused model saved to: {save_path}\")\n",
    "\n",
    "    return fused_model\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def train_student_model(teacher_models, student_model, dataloader, optimizer, loss_fn, device='cpu'):\n",
    "    \"\"\"\n",
    "    Trains a student model using knowledge distillation from teacher models.\n",
    "\n",
    "    Parameters:\n",
    "        teacher_models (list): List of pre-trained teacher models.\n",
    "        student_model (torch.nn.Module): The student model to be trained.\n",
    "        dataloader (DataLoader): DataLoader for the training data.\n",
    "        optimizer (torch.optim.Optimizer): Optimizer for the student model.\n",
    "        loss_fn (function): Loss function (e.g., KL divergence or cross-entropy).\n",
    "        device (str): Device to use ('cpu' or 'cuda').\n",
    "\n",
    "    Returns:\n",
    "        student_model: Trained student model.\n",
    "    \"\"\"\n",
    "    student_model.to(device)\n",
    "    for model in teacher_models:\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "\n",
    "    student_model.train()\n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Get predictions from all teacher models\n",
    "        teacher_outputs = [F.softmax(model(images), dim=1) for model in teacher_models]\n",
    "\n",
    "        # Average the softmax predictions to create soft labels\n",
    "        soft_labels = torch.stack(teacher_outputs).mean(dim=0)\n",
    "\n",
    "        # Forward pass through the student model\n",
    "        student_outputs = student_model(images)\n",
    "\n",
    "        # Compute knowledge distillation loss\n",
    "        loss = loss_fn(student_outputs, soft_labels)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return student_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacr",
   "language": "python",
   "name": "spacr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
