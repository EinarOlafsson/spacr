{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d7fe6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacr\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch_geometric.loader import DataLoader, NeighborSampler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch.nn import Linear\n",
    "\n",
    "def generate_graph(gene_df, cell_df):\n",
    "    # Ensure the dataframes are sorted to maintain consistent ordering\n",
    "    gene_df = gene_df.sort_values(by=['gene_id', 'well_id'])\n",
    "    cell_df = cell_df.sort_values(by=['cell_id', 'well_id'])\n",
    "    \n",
    "    # Map gene_id and cell_id to unique indices for graph construction\n",
    "    gene_id_to_index = {gene_id: idx for idx, gene_id in enumerate(gene_df.gene_id.unique())}\n",
    "    cell_id_to_index = {cell_id: idx+len(gene_id_to_index) for idx, cell_id in enumerate(cell_df.cell_id.unique())}\n",
    "\n",
    "    # Creating a mapping from well_id to gene fractions\n",
    "    well_to_gene_fractions = gene_df.groupby('well_id').apply(lambda x: dict(zip(x.gene_id, x.well_read_fraction))).to_dict()\n",
    "\n",
    "    # Prepare edges and edge attributes\n",
    "    edge_index = []\n",
    "    edge_attr = []\n",
    "    # Cell scores as labels\n",
    "    cell_scores = []\n",
    "\n",
    "    for _, cell_row in cell_df.iterrows():\n",
    "        cell_idx = cell_id_to_index[cell_row['cell_id']]\n",
    "        cell_scores.append(cell_row['score'])  # Add cell score to labels list\n",
    "        if cell_row['well_id'] in well_to_gene_fractions:\n",
    "            for gene_id, fraction in well_to_gene_fractions[cell_row['well_id']].items():\n",
    "                if gene_id in gene_id_to_index:  # Check if gene is in the index map\n",
    "                    gene_idx = gene_id_to_index[gene_id]\n",
    "                    edge_index.append([cell_idx, gene_idx])  # Note the order: cell to gene\n",
    "                    edge_attr.append(fraction)\n",
    "\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    edge_attr = torch.tensor(edge_attr, dtype=torch.float).view(-1, 1)\n",
    "    cell_scores = torch.tensor(cell_scores, dtype=torch.float)\n",
    "\n",
    "    # Node features for genes could be one-hot encoded or gene fractions; placeholder for now\n",
    "    gene_features = torch.eye(len(gene_id_to_index))  # One-hot encoding of genes as placeholder\n",
    "    cell_features = torch.zeros(len(cell_id_to_index), gene_features.size(1))  # Placeholder for cell features\n",
    "\n",
    "    # Combine features for all nodes\n",
    "    x = torch.cat([cell_features, gene_features], dim=0)  # Ensure cell features come first to align with cell_scores\n",
    "\n",
    "    data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=cell_scores)\n",
    "\n",
    "    # Return both the graph data and the gene_id_to_index dictionary\n",
    "    return data, gene_id_to_index\n",
    "\n",
    "    \n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, feature_size):\n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = SAGEConv(feature_size, 16)\n",
    "        self.conv2 = SAGEConv(16, 32)\n",
    "        self.out = Linear(32, 1)\n",
    "\n",
    "    def forward(self, x, edge_index=None, adjs=None):\n",
    "        if adjs is None:\n",
    "            # Assume full graph processing for feature importance evaluation\n",
    "            x = F.relu(self.conv1(x, edge_index))\n",
    "            x = F.dropout(x, training=self.training)\n",
    "            x = F.relu(self.conv2(x, edge_index))\n",
    "        else:\n",
    "            # Batch processing with NeighborSampler\n",
    "            for i, (edge_index, _, size) in enumerate(adjs):\n",
    "                x_target = x[:size[1]]  # Target nodes for this layer\n",
    "                if i == 0:\n",
    "                    x = self.conv1((x, x_target), edge_index)\n",
    "                else:\n",
    "                    x = self.conv2((x, x_target), edge_index)\n",
    "                x = F.relu(x)\n",
    "                x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "def train_gnn(graph_data, model_save_path, feature_size, lr, epochs, batch_size, size):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    model = GNN(feature_size=feature_size).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    graph_data = graph_data.to(device)\n",
    "    train_loader = NeighborSampler(graph_data.edge_index,\n",
    "                                   node_idx=None,\n",
    "                                   sizes=[size, size],\n",
    "                                   batch_size=batch_size,\n",
    "                                   shuffle=True,\n",
    "                                   drop_last=False)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch_data in train_loader:\n",
    "            batch_size, n_id, adjs = batch_data\n",
    "            adjs = [adj.to(device) for adj in adjs]  # Ensure adjs are on the correct device\n",
    "            optimizer.zero_grad()\n",
    "            out = model(x=graph_data.x[n_id], adjs=adjs)  # Correctly pass adjs\n",
    "            loss = criterion(out, graph_data.y[n_id[:batch_size]])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f'Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}', end='\\r', flush=True)\n",
    "    del optimizer, criterion, train_loader, batch_data\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98a5a460",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph_data.y shape: torch.Size([710938])\n",
      "original_preds shape: torch.Size([712070])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [710938, 712070]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model_save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/olafsson/Desktop/gnn/mode.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mcompute_gene_importance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgraph_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mmodel_save_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mn_permutations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36mcompute_gene_importance\u001b[0;34m(model, graph_data, model_save_path, n_permutations)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moriginal_preds shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, original_preds\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    144\u001b[0m \u001b[38;5;66;03m# Compute MSE after ensuring dimensions match\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m original_mse \u001b[38;5;241m=\u001b[39m \u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal_preds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m importances \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    148\u001b[0m feature_size \u001b[38;5;241m=\u001b[39m graph_data\u001b[38;5;241m.\u001b[39mnum_features\n",
      "File \u001b[0;32m~/anaconda3/envs/spacr_package/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/spacr_package/lib/python3.9/site-packages/sklearn/metrics/_regression.py:497\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m squared:\n\u001b[1;32m    493\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m root_mean_squared_error(\n\u001b[1;32m    494\u001b[0m             y_true, y_pred, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, multioutput\u001b[38;5;241m=\u001b[39mmultioutput\n\u001b[1;32m    495\u001b[0m         )\n\u001b[0;32m--> 497\u001b[0m y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    501\u001b[0m output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage((y_true \u001b[38;5;241m-\u001b[39m y_pred) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, weights\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[0;32m~/anaconda3/envs/spacr_package/lib/python3.9/site-packages/sklearn/metrics/_regression.py:102\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_reg_targets\u001b[39m(y_true, y_pred, multioutput, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     69\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m        correct keyword.\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    104\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m check_array(y_pred, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/anaconda3/envs/spacr_package/lib/python3.9/site-packages/sklearn/utils/validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    460\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [710938, 712070]"
     ]
    }
   ],
   "source": [
    "model_save_path = '/home/olafsson/Desktop/gnn/mode.pth'\n",
    "compute_gene_importance(model,\n",
    "                        graph_data,\n",
    "                        model_save_path,\n",
    "                        n_permutations=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f0bf3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_id</th>\n",
       "      <th>well_id</th>\n",
       "      <th>well_read_fraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TGGT1_313050_2</td>\n",
       "      <td>p1_r1_c1</td>\n",
       "      <td>0.274431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TGGT1_207865_1</td>\n",
       "      <td>p1_r1_c1</td>\n",
       "      <td>0.249161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TGGT1_409250_65</td>\n",
       "      <td>p1_r1_c1</td>\n",
       "      <td>0.159549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TGGT1_212410_369</td>\n",
       "      <td>p1_r1_c1</td>\n",
       "      <td>0.102387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TGGT1_239600_2</td>\n",
       "      <td>p1_r1_c1</td>\n",
       "      <td>0.068351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17735</th>\n",
       "      <td>TGGT1_269885A_3</td>\n",
       "      <td>p2_r5_c10</td>\n",
       "      <td>0.061794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17736</th>\n",
       "      <td>TGGT1_235140_3</td>\n",
       "      <td>p2_r5_c2</td>\n",
       "      <td>0.259861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17737</th>\n",
       "      <td>TGGT1_000000_14</td>\n",
       "      <td>p2_r5_c2</td>\n",
       "      <td>0.252900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17738</th>\n",
       "      <td>TGGT1_310010_1</td>\n",
       "      <td>p2_r5_c2</td>\n",
       "      <td>0.250580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17739</th>\n",
       "      <td>TGGT1_239600_3</td>\n",
       "      <td>p2_r5_c2</td>\n",
       "      <td>0.236659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17740 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                gene_id    well_id  well_read_fraction\n",
       "0        TGGT1_313050_2   p1_r1_c1            0.274431\n",
       "1        TGGT1_207865_1   p1_r1_c1            0.249161\n",
       "2       TGGT1_409250_65   p1_r1_c1            0.159549\n",
       "3      TGGT1_212410_369   p1_r1_c1            0.102387\n",
       "4        TGGT1_239600_2   p1_r1_c1            0.068351\n",
       "...                 ...        ...                 ...\n",
       "17735   TGGT1_269885A_3  p2_r5_c10            0.061794\n",
       "17736    TGGT1_235140_3   p2_r5_c2            0.259861\n",
       "17737   TGGT1_000000_14   p2_r5_c2            0.252900\n",
       "17738    TGGT1_310010_1   p2_r5_c2            0.250580\n",
       "17739    TGGT1_239600_3   p2_r5_c2            0.236659\n",
       "\n",
       "[17740 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_id</th>\n",
       "      <th>well_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p1_r10_c10_f1_o123</td>\n",
       "      <td>p1_r10_c10</td>\n",
       "      <td>0.999409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p1_r10_c10_f1_o159</td>\n",
       "      <td>p1_r10_c10</td>\n",
       "      <td>0.998264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p1_r10_c10_f2_o120</td>\n",
       "      <td>p1_r10_c10</td>\n",
       "      <td>0.998019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p1_r10_c10_f3_o48</td>\n",
       "      <td>p1_r10_c10</td>\n",
       "      <td>0.998897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p1_r10_c10_f3_o70</td>\n",
       "      <td>p1_r10_c10</td>\n",
       "      <td>0.013018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710933</th>\n",
       "      <td>p9_r9_c9_f9_o50</td>\n",
       "      <td>p9_r9_c9</td>\n",
       "      <td>0.041357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710934</th>\n",
       "      <td>p9_r9_c9_f9_o80</td>\n",
       "      <td>p9_r9_c9</td>\n",
       "      <td>0.001581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710935</th>\n",
       "      <td>p9_r9_c9_f9_o81</td>\n",
       "      <td>p9_r9_c9</td>\n",
       "      <td>0.005244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710936</th>\n",
       "      <td>p9_r9_c9_f9_o86</td>\n",
       "      <td>p9_r9_c9</td>\n",
       "      <td>0.406849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710937</th>\n",
       "      <td>p9_r9_c9_f9_o91</td>\n",
       "      <td>p9_r9_c9</td>\n",
       "      <td>0.007924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>710938 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   cell_id     well_id     score\n",
       "0       p1_r10_c10_f1_o123  p1_r10_c10  0.999409\n",
       "1       p1_r10_c10_f1_o159  p1_r10_c10  0.998264\n",
       "2       p1_r10_c10_f2_o120  p1_r10_c10  0.998019\n",
       "3        p1_r10_c10_f3_o48  p1_r10_c10  0.998897\n",
       "4        p1_r10_c10_f3_o70  p1_r10_c10  0.013018\n",
       "...                    ...         ...       ...\n",
       "710933     p9_r9_c9_f9_o50    p9_r9_c9  0.041357\n",
       "710934     p9_r9_c9_f9_o80    p9_r9_c9  0.001581\n",
       "710935     p9_r9_c9_f9_o81    p9_r9_c9  0.005244\n",
       "710936     p9_r9_c9_f9_o86    p9_r9_c9  0.406849\n",
       "710937     p9_r9_c9_f9_o91    p9_r9_c9  0.007924\n",
       "\n",
       "[710938 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1132"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequencing = '/mnt/data/CellVoyager/20x/tsg101/crispr_screen/all/measurements/sequencing.csv'\n",
    "score = '/mnt/data/CellVoyager/20x/tsg101/crispr_screen/all/measurements/dv_cell.csv'\n",
    "\n",
    "# Example loading step\n",
    "gene_df = pd.read_csv(sequencing)\n",
    "cell_df = pd.read_csv(score)\n",
    "\n",
    "gene_df = gene_df.rename(columns={\"prc\": \"well_id\", \"grna\": \"gene_id\", \"count\": \"read_count\"})\n",
    "gene_df = gene_df.drop(columns=['Unnamed: 0', 'plate', 'row', 'col', 'grna_seq', 'gene'])\n",
    "total_reads_per_well = gene_df.groupby('well_id')['read_count'].sum().reset_index(name='total_reads')\n",
    "gene_df = gene_df.merge(total_reads_per_well, on='well_id')\n",
    "gene_df['well_read_fraction'] = gene_df['read_count']/gene_df['total_reads']\n",
    "gene_df = gene_df.drop(columns=['read_count', 'total_reads'])\n",
    "\n",
    "cell_df = cell_df.rename(columns={\"prcfo\": \"cell_id\", \"prc\": \"well_id\", \"pred\": \"score\"})\n",
    "cell_df = cell_df.drop(columns=['parasite_area', 'parasite_area', 'recruitment'])\n",
    "display(gene_df)\n",
    "display(cell_df)\n",
    "feature_size = len(gene_df['gene_id'].unique())\n",
    "feature_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff96828c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_size: 1132\n"
     ]
    }
   ],
   "source": [
    "print(f'feature_size: {feature_size}')\n",
    "graph_data, gene_id_to_index = generate_graph(gene_df,cell_df)\n",
    "dict_file_path = '/home/olafsson/Desktop/gnn/dict.pth'\n",
    "\n",
    "with open(dict_file_path, 'wb') as file:\n",
    "    pickle.dump(gene_id_to_index, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c9e9fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10000, Loss: 0.1930284325854253\r"
     ]
    }
   ],
   "source": [
    "model = train_gnn(graph_data,\n",
    "                  model_save_path='/home/olafsson/Desktop/gnn/mode.pth',\n",
    "                  feature_size=feature_size,\n",
    "                  lr=0.001,\n",
    "                  epochs=10000,\n",
    "                  batch_size=2048,\n",
    "                  size=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c3cd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\u001b[2K\n",
    "\u001b[2K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0709f00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6803e92a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0355d183",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1338b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd28be71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_graph(data):\n",
    "    G = nx.Graph()\n",
    "    edge_index = data.edge_index.cpu().numpy()\n",
    "    # Add edges\n",
    "    for i in range(edge_index.shape[1]):\n",
    "        source = edge_index[0, i]\n",
    "        target = edge_index[1, i]\n",
    "        G.add_edge(source, target)\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    nx.draw(G, with_labels=True, node_color='lightblue', edge_color='gray', node_size=50, font_size=6)\n",
    "    plt.show()\n",
    "    \n",
    "# Define a simple GNN model\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, feature_size):\n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = SAGEConv(feature_size, 16)\n",
    "        self.conv2 = SAGEConv(16, 32)\n",
    "        self.out = Linear(32, 1)  # The output size here aligns with the final layer's output\n",
    "\n",
    "    def forward(self, x, adjs):\n",
    "        # adjs is a list of tuples provided by NeighborSampler, each for a layer\n",
    "        for i, (edge_index, _, size) in enumerate(adjs):\n",
    "            x_target = x[:size[1]]  # Target nodes for this layer\n",
    "            if i == 0:\n",
    "                x = self.conv1((x, x_target), edge_index)\n",
    "            else:\n",
    "                x = self.conv2((x, x_target), edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        # Apply the final linear transformation\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "def train_gnn(graph_data, feature_size, lr=0.01, epochs=100, batch_size=1024, size=100):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    model = GNN(feature_size=feature_size).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    # Assume graph_data already in device\n",
    "    graph_data = graph_data.to(device)\n",
    "\n",
    "    # Set up the NeighborSampler\n",
    "    # Here, you need to define the sizes of the neighborhoods for each layer\n",
    "    # This is just an example configuration\n",
    "    train_loader = NeighborSampler(\n",
    "        graph_data.edge_index,\n",
    "        node_idx=None,  # sample from the entire graph; adjust as needed\n",
    "        sizes=[size, size],  # Sizes of the neighborhoods for each layer\n",
    "        batch_size=batch_size,  # Adjust based on your GPU memory and task\n",
    "        shuffle=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch_size, n_id, adjs in train_loader:\n",
    "            adjs = [adj.to(device) for adj in adjs]\n",
    "            optimizer.zero_grad()\n",
    "            out = model(graph_data.x[n_id], adjs)  # Note the adjustment here\n",
    "            loss = criterion(out, graph_data.y[n_id[:batch_size]])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        print(f'Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}', end='\\r', flush=True)\n",
    "    return model\n",
    "\n",
    "def generate_graph_v1(gene_df, cell_df):\n",
    "    # Ensure the dataframes are sorted to maintain consistent ordering\n",
    "    gene_df = gene_df.sort_values(by=['gene_id', 'well_id'])\n",
    "    cell_df = cell_df.sort_values(by=['cell_id', 'well_id'])\n",
    "    \n",
    "    # Map gene_id and cell_id to unique indices for graph construction\n",
    "    gene_id_to_index = {gene_id: idx for idx, gene_id in enumerate(gene_df.gene_id.unique())}\n",
    "    cell_id_to_index = {cell_id: idx+len(gene_id_to_index) for idx, cell_id in enumerate(cell_df.cell_id.unique())}\n",
    "\n",
    "    # Creating a mapping from well_id to gene fractions\n",
    "    well_to_gene_fractions = gene_df.groupby('well_id').apply(lambda x: dict(zip(x.gene_id, x.well_read_fraction))).to_dict()\n",
    "\n",
    "    # Prepare edges and edge attributes\n",
    "    edge_index = []\n",
    "    edge_attr = []\n",
    "    # Cell scores as labels\n",
    "    cell_scores = []\n",
    "\n",
    "    for _, cell_row in cell_df.iterrows():\n",
    "        cell_idx = cell_id_to_index[cell_row['cell_id']]\n",
    "        cell_scores.append(cell_row['score'])  # Add cell score to labels list\n",
    "        if cell_row['well_id'] in well_to_gene_fractions:\n",
    "            for gene_id, fraction in well_to_gene_fractions[cell_row['well_id']].items():\n",
    "                if gene_id in gene_id_to_index:  # Check if gene is in the index map\n",
    "                    gene_idx = gene_id_to_index[gene_id]\n",
    "                    edge_index.append([cell_idx, gene_idx])  # Note the order: cell to gene\n",
    "                    edge_attr.append(fraction)\n",
    "\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    edge_attr = torch.tensor(edge_attr, dtype=torch.float).view(-1, 1)\n",
    "    cell_scores = torch.tensor(cell_scores, dtype=torch.float)\n",
    "\n",
    "    # Node features for genes could be one-hot encoded or gene fractions; placeholder for now\n",
    "    gene_features = torch.eye(len(gene_id_to_index))  # One-hot encoding of genes as placeholder\n",
    "    cell_features = torch.zeros(len(cell_id_to_index), gene_features.size(1))  # Placeholder for cell features\n",
    "\n",
    "    # Combine features for all nodes\n",
    "    x = torch.cat([cell_features, gene_features], dim=0)  # Ensure cell features come first to align with cell_scores\n",
    "\n",
    "    data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=cell_scores)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9daac606",
   "metadata": {},
   "outputs": [],
   "source": [
    "'pip install torch-sparse -f https://data.pyg.org/whl/torch-2.2.1+cu121.html'\n",
    "'pip install torch-scatter -f https://data.pyg.org/whl/torch-2.2.1+cu121.html'\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacr_package",
   "language": "python",
   "name": "spacr_package"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
